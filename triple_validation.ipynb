{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triple validation with SVM and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook contains an continuation on effort to extract RDF triples from raw text and focuses on the next step in the process - validation (classifiacation) of the extracted triples. Informatin on the extraction method can be found [here](https://github.com/radev2711/DataScience/blob/main/Triples_from_text.ipynb).\n",
    "\n",
    "#### Triples\n",
    "\n",
    "A semantic triple is the core data entity in the Resource Description Framework (RDF) data model. It it a statement that repesents semantic data in a set of three entites in the subject–predicate–object format. Every entitry in the triple has it own unique URI. This format enables knowledge to be represented in a machine-readable way, thus allowing machines to querie and reasone about semantic data. \n",
    "\n",
    "In the subject–predicate–object format in the example *turtles are reptiles* the subject (sometimes called head) and the object (sometimes called tail) represent two entities being related; the predicate represents the nature of their relationship. This is similar to knowledge representations in graphs were the subject and the object will be nodes and the predicate will be edge (arc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "\n",
    "The naive Bayes classifiers are a family of linear \"probabilistic classifiers\" based on applying Bayes' theorem, which describes the probability of an event, based on prior knowledge of conditions that might be related to the event, with strong (naive) independence assumptions between the features minimizing the probability of misclassification.\n",
    "\n",
    "Naive Bayes classifiers are highly scalable, requirie a number of parameters linear in the number of features in a learning problem. The construction of these classifiers can be defined as simple: models assign class labels to instances, represented as vectors of feature values, where the class labels are drawn from some finite set. All naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class variable.\n",
    "\n",
    "In many practical applications, parameter estimation for naive Bayes models uses the method of maximum likelihood.\n",
    "\n",
    "Despite their naive design and apparently oversimplified assumptions, naive Bayes classifiers have worked quite well in many complex real-world situations. An advantage of this approach is that it only requires a small amount of training data to estimate the parameters necessary for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines\n",
    "\n",
    "Support vector machines (SVMs) are supervised learning models in machine learning, with associated learning algorithms that analyze data for classification and regression analysis. The SVMs are one of the most robust prediction methods, being based on statistical learning frameworks or Vapnik–Chervonenkis theory (VC) theory. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier. The SVM maps training examples to points in space so as to maximise the width of the gap between the two categories. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.\n",
    "\n",
    "In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces. This allows the algorithm to fit the maximum-margin hyperplane in a transformed feature space. Some of the common kernels include the Gaussian radial basis function and Polinomial kernel.\n",
    "\n",
    "The polynomial kernel is a function that represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables, allowing learning of non-linear models. This kernel looks not only at the given features of input samples to determine their similarity, but also combinations of these (interaction features). The feature space of a polynomial kernel is equivalent to that of polynomial regression, but without the combinatorial blowup in the number of parameters to be learned. When the input features are binary-valued (booleans), then the features correspond to logical conjunctions of input features.\n",
    "\n",
    "The radial basis function (RBF) kernel is a function, that computes the similarity between two points or how close they are to each other. The value of the RBF kernel decreases with distance and ranges between zero and one where zere denotes that the two points are the same. The RBF Kernel is popular because of its similarity to K-Nearest Neighborhood Algorithm. It has the advantages of K-NN and overcomes the space complexity problem as RBF Kernel Support Vector Machines just needs to store the support vectors during training and not the entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triple Validation\n",
    "\n",
    "Triple classification or validation aims to judge whether a given triple is correct or not, which is a binary classification task. \n",
    "\n",
    "#### Data\n",
    "\n",
    "The data consists of an csv file containig output from method extracting triples from raw text. The labels are manually added to the data.\n",
    "\n",
    "There is no true testing data set, but there is small set for human evaluation containig 10 pairs of negative/possitive triples. These pairs were made by removing negative triples from the initial dataset and editing them to become possitive. The triples were removed to ensure that the model has not been tained ot validated on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainig classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report #precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_data = pd.read_csv('data/train_triples.csv', names=['triple', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, lets see the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luck can plot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use is period</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sword is swordsmanship</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>system are size</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spear is thrower</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>light is interaction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>size be mass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>month has group</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>problem be number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>dion had slave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2063 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      triple  label\n",
       "0              luck can plot      0\n",
       "1              use is period      0\n",
       "2     sword is swordsmanship      0\n",
       "3            system are size      0\n",
       "4           spear is thrower      0\n",
       "...                      ...    ...\n",
       "2058    light is interaction      0\n",
       "2059            size be mass      0\n",
       "2060         month has group      0\n",
       "2061       problem be number      0\n",
       "2062          dion had slave      0\n",
       "\n",
       "[2063 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels correspond to negative example with label 0 and possitive exmple with label 1.\n",
    "\n",
    "The extraction method has high yeld, but with few possitive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1910\n",
       "1     153\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data does not have train-test split it is possible to use the splitter from scikit. Testing multiple models with the same data makes the test split validation set.\n",
    "\n",
    "The split is 80/20 to maximize the number of possitive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triples, validate_triples, train_labels, validate_labels = model_selection.train_test_split(triple_data['triple'], triple_data['label'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure that the validation labels contain positive class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    380\n",
       "1     33\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The triples column needs to be converted into vectors. Scikit learn offers Count Vectorizera and TF-IDF vectorizer. Lets test them and see who is able to help with the triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(triple_data['triple'])\n",
    "train_triple_tfidf = tfidf_vect.transform(train_triples)\n",
    "validate_triple_tfidf = tfidf_vect.transform(validate_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(triple_data['triple'])\n",
    "train_triple_count = count_vect.transform(train_triples)\n",
    "validate_triple_count = count_vect.transform(validate_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1464)\t0.6970607756375621\n",
      "  (0, 1345)\t0.6614612313135307\n",
      "  (0, 623)\t0.2767224503663339\n",
      "  (1, 1099)\t0.6916152959494455\n",
      "  (1, 710)\t0.20817436157587133\n",
      "  (1, 648)\t0.6916152959494455\n",
      "  (2, 1010)\t0.9595970239998503\n",
      "  (2, 623)\t0.281377951393905\n",
      "  (3, 1203)\t0.6916152959494455\n",
      "  (3, 795)\t0.6916152959494455\n",
      "  (3, 710)\t0.20817436157587133\n",
      "  (4, 1294)\t0.6251106533852683\n",
      "  (4, 887)\t0.6890891308601802\n",
      "  (4, 623)\t0.36659629124502086\n",
      "  (5, 991)\t0.6208267302626957\n",
      "  (5, 827)\t0.699496567998095\n",
      "  (5, 116)\t0.3539473440361099\n",
      "  (6, 1469)\t0.6873813688372215\n",
      "  (6, 1276)\t0.6216279272720678\n",
      "  (6, 173)\t0.37561359641378883\n",
      "  (7, 1489)\t0.7531696638101186\n",
      "  (7, 710)\t0.21512417643155518\n",
      "  (7, 382)\t0.6216566948330872\n",
      "  (8, 1123)\t0.8190873899151332\n",
      "  (8, 980)\t0.5237960861091602\n",
      "  (8, 710)\t0.2339519349326691\n",
      "  (9, 1518)\t0.7048112119987632\n",
      "  (9, 1517)\t0.6234670472114084\n",
      "  (9, 618)\t0.338422807272681\n"
     ]
    }
   ],
   "source": [
    "print(train_triple_tfidf[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 623)\t1\n",
      "  (0, 1345)\t1\n",
      "  (0, 1464)\t1\n",
      "  (1, 648)\t1\n",
      "  (1, 710)\t1\n",
      "  (1, 1099)\t1\n",
      "  (2, 623)\t1\n",
      "  (2, 1010)\t2\n",
      "  (3, 710)\t1\n",
      "  (3, 795)\t1\n",
      "  (3, 1203)\t1\n",
      "  (4, 623)\t1\n",
      "  (4, 887)\t1\n",
      "  (4, 1294)\t1\n",
      "  (5, 116)\t1\n",
      "  (5, 827)\t1\n",
      "  (5, 991)\t1\n",
      "  (6, 173)\t1\n",
      "  (6, 1276)\t1\n",
      "  (6, 1469)\t1\n",
      "  (7, 382)\t1\n",
      "  (7, 710)\t1\n",
      "  (7, 1489)\t1\n",
      "  (8, 710)\t1\n",
      "  (8, 980)\t1\n",
      "  (8, 1123)\t1\n",
      "  (9, 618)\t1\n",
      "  (9, 1517)\t1\n",
      "  (9, 1518)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_triple_count[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the count vectorizer returns only one score and the TF-IDF returns meaningful calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the triples as vectors it is time to train some models. The training set will be fitted on four classifiers - Naive Bayes and SVM with 3 types of kernel: linear, rbf and polynomial, to look for best performer or difference in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train naive Bayes\n",
    "naive = naive_bayes.MultinomialNB()\n",
    "naive.fit(train_triple_tfidf, train_labels)\n",
    "predictions_NB = naive.predict(validate_triple_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train leinear SVM\n",
    "svm_lin = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "svm_lin.fit(train_triple_tfidf, train_labels)\n",
    "predictions_SVM = svm_lin.predict(validate_triple_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gausean SVM\n",
    "rbf_svm = svm.SVC(kernel='rbf', gamma=0.5, C=1.0)\n",
    "rbf_svm.fit(train_triple_tfidf, train_labels)\n",
    "rbf_pred = rbf_svm.predict(validate_triple_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train polinomial SVM\n",
    "poly_svm = svm.SVC(kernel='poly', degree=3, C=1)\n",
    "poly_svm.fit(train_triple_tfidf, train_labels)\n",
    "poly_pred = poly_svm.predict(validate_triple_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics of accuracy and F1 are the most commonly used when working with supervised machne learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  92.00968523002422\n",
      "Naive Bayes F1 Score ->  88.1807828181821\n",
      "SVM Linear Accuracy Score ->  91.76755447941889\n",
      "SVM Linear F1 Score ->  88.05977450045248\n",
      "SVM-RBF Accuracy Score ->  92.00968523002422\n",
      "SVM-RBF F1 Score ->  88.1807828181821\n",
      "SVM-POLY Accuracy Score ->  92.00968523002422\n",
      "SVM-POLY F1 Score ->  88.1807828181821\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Accuracy Score -> \", accuracy_score(validate_labels, predictions_NB )*100)\n",
    "print(\"Naive Bayes F1 Score -> \", f1_score(validate_labels, predictions_NB, average='weighted')*100)\n",
    "\n",
    "print(\"SVM Linear Accuracy Score -> \", accuracy_score(validate_labels, predictions_SVM)*100)\n",
    "print(\"SVM Linear F1 Score -> \", f1_score(validate_labels, predictions_SVM, average='weighted')*100)\n",
    "\n",
    "print(\"SVM-RBF Accuracy Score -> \", accuracy_score(validate_labels, rbf_pred)*100)\n",
    "print(\"SVM-RBF F1 Score -> \", f1_score(validate_labels, rbf_pred, average='weighted')*100)\n",
    "\n",
    "print(\"SVM-POLY Accuracy Score -> \", accuracy_score(validate_labels, poly_pred)*100)\n",
    "print(\"SVM-POLY F1 Score -> \", f1_score(validate_labels, poly_pred, average='weighted')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the one of the SVM models is slightly different than the others. With so little data the rest of the models work exactly the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring is informative and helps with selecting the best performing model, but lets test it with new data and look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_eval = pd.read_csv('data/triple_pairs.csv', names=['triple', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_triples = manual_eval['triple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_triples_tfidf = tfidf_vect.transform(me_triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the models perform equally lets select the Naive Bayes and one SVM model and vizualize their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions_svm = poly_svm.predict(predict_triples_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions_nb = naive.predict(predict_triples_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_eval['nb'] = new_predictions_nb\n",
    "manual_eval['svm'] = new_predictions_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple</th>\n",
       "      <th>label</th>\n",
       "      <th>nb</th>\n",
       "      <th>svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age had horse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horse has age</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maple have leave</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maple have leaf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mountain are summit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mountain has summit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>culture is proto-indo-europeans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>culture is proto-indo-european</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sword are thrusting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sword is thrusting</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vehicle having wheel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vehicle have wheel</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chainmail is type</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chainmail is armor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>power is surge</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>power can surge</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>piano is keyboard</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>piano has keyboard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>earthquake was epicenter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>earthquake has epicenter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             triple  label  nb  svm\n",
       "0                     age had horse      0   0    0\n",
       "1                     horse has age      1   0    0\n",
       "2                  maple have leave      0   0    0\n",
       "3                   maple have leaf      1   0    0\n",
       "4               mountain are summit      0   0    0\n",
       "5               mountain has summit      1   0    0\n",
       "6   culture is proto-indo-europeans      0   0    0\n",
       "7    culture is proto-indo-european      1   0    0\n",
       "8               sword are thrusting      0   0    0\n",
       "9                sword is thrusting      1   0    0\n",
       "10             vehicle having wheel      0   0    0\n",
       "11               vehicle have wheel      1   0    0\n",
       "12                chainmail is type      0   0    0\n",
       "13               chainmail is armor      1   0    0\n",
       "14                   power is surge      0   0    0\n",
       "15                  power can surge      1   0    0\n",
       "16                piano is keyboard      0   0    0\n",
       "17               piano has keyboard      1   0    0\n",
       "18         earthquake was epicenter      0   0    0\n",
       "19         earthquake has epicenter      1   0    0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models predict only the negative class. Maybe a classifiacation report will help with expainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1530\n",
      "           1       1.00      0.70      0.82       120\n",
      "\n",
      "    accuracy                           0.98      1650\n",
      "   macro avg       0.99      0.85      0.91      1650\n",
      "weighted avg       0.98      0.98      0.98      1650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test = poly_svm.predict(train_triple_tfidf)\n",
    "print(classification_report(train_labels, train_test, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the low number of possitive triples affects the recall of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlusion\n",
    "\n",
    "The results show that the models learn only the negative class. The triple validation comes after a highly productive extraction method that results in low amount of positive examlples. The nature of the task is such that new data can be added, but the ratio of possitive examples will remain around 10% from the total number of extracted triples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "\n",
    "[SVM](https://en.wikipedia.org/wiki/Support_vector_machine)\n",
    "\n",
    "[Text classification with SVM](https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34)\n",
    "\n",
    "[SVM multyclass classification](https://www.baeldung.com/cs/svm-multiclass-classification)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
