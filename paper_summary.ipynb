{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiating Concepts and Instances for Knowledge Graph Embedding\n",
    "\n",
    "## Xin Lv, Lei Hou, Juanzi Li, Zhiyuan Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Paper PDF](https://arxiv.org/pdf/1811.04588v1.pdf)\n",
    "\n",
    "[Paper Code](https://github.com/davidlvxin/TransC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper describes a novel knowledge graph embedding model named TransC with the purpose of embedding knowledge that keeps the differentiation of concepts and instances. The TransC approach models the concepts in the knowledge graph as a sphere in the semantic space and each instance as a vector in the same space. The relations between concepts and instances and between concepts and sub-concepts are modeled by their relative positions. The model was tested on dataset based on YAGO knowledge base and the results show that the model captures the semantic link between instanceOf and subClassOf relation, while other knowledge embedding models split the relation between concept and instance.\n",
    "\n",
    "The approach proposed by the authors consists of defining a different loss functions to measure the relative positions in embedding space, and then jointly learn the representations of concepts, instances, and relations based on the translation-based models. The tree loss functions are designed as: 1) loss function for _instanceOf_ triple representation $f_e(i,c) = ||i-p||_2 - m$ where _i_ must be inside the sphere _s_; 2) loss function for _subClassOf_ triple representation $d = ||p_i - p_j||_2$ where the relation is measured between the centres of the spheres and 3) loss function for relational triple representation $f_r(h,t) = ||h + r - t||_2^2$ where can be concluded that if _i_ is in sphere *$s_1$* and *$s_1$* is in *$s_2$* then there is a relation between _i_ and *$s_2$*.\n",
    "\n",
    "The method is evaluated on two tasks commonly used in knowledge graph embedding: link prediction and triple classification. For testing a dataset with triples from YAGO and newly created triples is composed. For the link predictions task the model proposes a ranked list of candidates for the head (h) given the triple (h,r,t). The classification task aims to predict if a triple is valid or not. For this a dataset with equal number of true and negative triples is created. \n",
    "\n",
    "The authors of the paper conclude that the proposed model TransC for knowledge embedding can handle instances, concepts, and relations in the same space to deal with the transitivity of isA relations. Results from experiments show that TransC outperforms previous translation-based models in most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "#import argparse\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "#import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, pnorm=0):\n",
    "    if pnorm == 1:\n",
    "        return torch.sum(torch.abs(x), -1)\n",
    "    else:\n",
    "        return torch.sum(x**2,-1)\n",
    "\n",
    "def normalize_emb(x):\n",
    "    # return  x/float(length)\n",
    "    veclen = torch.clamp_min_(torch.norm(x, 2, -1,keepdim=True), 1.0)\n",
    "    ret = x/veclen\n",
    "    return ret.detach()\n",
    "\n",
    "def normalize_radius(x):\n",
    "    return torch.clamp(x,min=-1.0,max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, args):\n",
    "        self.dataset_name = args[\"dataset\"]\n",
    "        self.args = args\n",
    "        self.entity_num, self.entity2id = self.read_file(self.dataset_name, \"instance2id\")\n",
    "        self.relation_num, self.relation2id = self.read_file(self.dataset_name, \"relation2id\")\n",
    "        self.concept_num, self.concept2id = self.read_file(self.dataset_name, \"concept2id\")\n",
    "        self.triple_num, self.triples = self.read_triples(self.dataset_name, \"triple2id\")\n",
    "\n",
    "        self.fb_h, self.fb_t, self.fb_r = [], [], []\n",
    "        self.relation_vec,self.entity_vec,self.concept_vec = [],[],[]\n",
    "        self.relation_tmp, self.entity_tmp, self.concept_tmp = [], [], []\n",
    "        self.concept_r, self.concept_r_tmp = [], []\n",
    "        self.ok = {}\n",
    "        self.subClassOf_ok = {}\n",
    "        self.instanceOf_ok = {}\n",
    "        self.subClassOf = []\n",
    "        self.instanceOf = []\n",
    "        self.instance_concept = [[] for i in range(self.entity_num)]\n",
    "        self.concept_instance = [[] for i in range(self.concept_num)]\n",
    "        self.sub_up_concept = [[] for i in range(self.concept_num)]\n",
    "        self.up_sub_concept = [[] for i in range(self.concept_num)]\n",
    "\n",
    "\n",
    "    def read_file(self, dataset,filename,split = 'Train'):\n",
    "        with open(\"data/\" + dataset + \"/\" + split+\"/\"+filename + \".txt\") as file:\n",
    "            L = file.readlines()\n",
    "            num = int(L[0].strip())\n",
    "            contents = [[x for x in line.strip().split()] for line in L[1:]]\n",
    "        return num, contents\n",
    "\n",
    "    def read_triples(self, dataset,filename,split = 'Train'):\n",
    "        with open(\"data/\" + dataset + \"/\" + split+\"/\"+filename + \".txt\") as file:\n",
    "            L = file.readlines()\n",
    "            num = int(L[0].strip())\n",
    "            contents = [[int(x) for x in line.strip().split()] for line in L[1:]]\n",
    "        return num, contents\n",
    "\n",
    "    def read_biples(self, dataset, filename,split = 'Train'):\n",
    "        with open(\"data/\" + dataset + \"/\" + split+\"/\"+filename + \".txt\") as file:\n",
    "            L = file.readlines()\n",
    "            contents = [[int(x) for x in line.strip().split()] for line in L[1:]]\n",
    "        return contents\n",
    "\n",
    "    def addHrt(self, x, y, z):  # x: head ,y: tail, z:relation\n",
    "        self.fb_h.append(x)\n",
    "        self.fb_r.append(z)\n",
    "        self.fb_t.append(y)\n",
    "        if (x, z) not in self.ok:\n",
    "            self.ok[(x, z)] = {y: 1}\n",
    "        else:\n",
    "            self.ok[(x, z)][y] = 1\n",
    "\n",
    "    def addSubClassOf(self, sub, parent):\n",
    "        self.subClassOf.append([sub, parent])\n",
    "        self.subClassOf_ok[(sub, parent)] = 1\n",
    "\n",
    "    def addInstanceOf(self, instance, concept):\n",
    "        self.instanceOf.append([instance, concept])\n",
    "        self.instanceOf_ok[(instance, concept)] = 1\n",
    "\n",
    "    def setup(self):\n",
    "        self.left_entity = [Counter() for i in range(self.relation_num)]\n",
    "        self.right_entity = [Counter() for i in range(self.relation_num)]\n",
    "\n",
    "        for h, t, r in self.triples:\n",
    "            self.addHrt(h, t, r)\n",
    "            if self.args[\"bern\"]:\n",
    "                self.left_entity[r][h] += 1\n",
    "                self.right_entity[r][t] += 1\n",
    "\n",
    "        self.left_num = [float(sum(c.values())) / float(len(c)) for c in self.left_entity]\n",
    "        self.right_num = [float(sum(c.values())) / float(len(c)) for c in self.right_entity]\n",
    "\n",
    "        self.instanceOf_contents = self.read_biples(self.args[\"dataset\"], \"instanceOf2id\")\n",
    "        self.subClassOf_contents = self.read_biples(self.args[\"dataset\"], \"subClassOf2id\")\n",
    "\n",
    "        for a, b in self.instanceOf_contents:\n",
    "            self.addInstanceOf(a,b)\n",
    "            self.instance_concept[a].append(b)\n",
    "            self.concept_instance[b].append(a)\n",
    "\n",
    "        for a, b in self.subClassOf_contents:\n",
    "            self.addSubClassOf(a,b)\n",
    "            self.sub_up_concept[a].append(b)\n",
    "            self.up_sub_concept[b].append(a)\n",
    "\n",
    "\n",
    "        self.instance_brother = [[ins for concept in concepts\n",
    "                                for ins in self.concept_instance[concept]\n",
    "                                if ins != instance_out]\n",
    "                                for instance_out, concepts\n",
    "                                in enumerate(self.instance_concept)]\n",
    "\n",
    "        self.concept_brother = [[sub for up in ups\n",
    "                                for sub in self.up_sub_concept[up]\n",
    "                                if sub != sub_out]\n",
    "                                for sub_out, ups\n",
    "                                in enumerate(self.sub_up_concept)]\n",
    "\n",
    "        self.trainSize = len(self.fb_h) + len(self.instanceOf) + len(self.subClassOf)\n",
    "\n",
    "        print(\"train size {} {} {} {}\".format(self.trainSize, len(self.fb_h),len(self.instanceOf),len(self.subClassOf)))\n",
    "\n",
    "    def save(self,):\n",
    "        with open(\"data/\" + self.dataset_name + \"/\" + self.args[\"split\"] + \"/processed.pkl\",'wb') as file:\n",
    "            pkl.dump(self, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed(dataset_name,split):\n",
    "    with open(\"data/\" + dataset_name + \"/\" + split + \"/processed.pkl\",'rb') as file:\n",
    "        res = pkl.load(file)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train(nn.Module):\n",
    "    def __init__(self,args,dataset):\n",
    "        super(Train, self).__init__()\n",
    "        self.args = args\n",
    "        self.D = dataset\n",
    "        self.entity_vec = nn.Embedding(self.D.entity_num,args[\"emb_dim\"])\n",
    "        self.concept_vec = nn.Embedding(self.D.concept_num,args[\"emb_dim\"]+1)\n",
    "        self.relation_vec = nn.Embedding(self.D.relation_num,args[\"emb_dim\"])\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(),lr=args[\"lr\"])\n",
    "\n",
    "        ## initialize\n",
    "        nn.init.normal_(self.entity_vec.weight.data, 0.0, 1.0 / args[\"emb_dim\"])\n",
    "        nn.init.normal_(self.relation_vec.weight.data, 0.0, 1.0 / args[\"emb_dim\"])\n",
    "        nn.init.normal_(self.concept_vec.weight.data[:, :-1], 0.0, 1.0 / args[\"emb_dim\"])\n",
    "        nn.init.uniform_(self.concept_vec.weight.data[:, -1], 0.0, 1.0)\n",
    "\n",
    "        # self.training_instance_file = open(\"data/cpp_training_instance.txt\", 'r')\n",
    "        # with open(\"data/cpp_training_instance.txt\", 'r') as file:\n",
    "        #     lines = file.readlines()\n",
    "        #     lines = [line.strip().split(\"\\t\") for line in lines]\n",
    "        #     self.training_instance = [[int(x) for x in line] for line in lines ]\n",
    "        #     print(\"using saved instances\")\n",
    "\n",
    "    def doTrain(self):\n",
    "        nbatches = self.args[\"nbatches\"]\n",
    "        nepoch = self.args[\"nepoch\"]\n",
    "        batchSize = int(self.D.trainSize / nbatches)\n",
    "        allreadyindex = 0\n",
    "\n",
    "        dis_a_L, dis_b_L = [], []\n",
    "        dis_count = 0\n",
    "        for epoch in range(nepoch):\n",
    "            res = 0\n",
    "            for batch in range(nbatches):\n",
    "                losses = []\n",
    "                stime = time.time()\n",
    "                pairs = [[], [], []]\n",
    "\n",
    "                #normalize\n",
    "                self.entity_vec.weight.data = normalize_emb(self.entity_vec.weight.data)\n",
    "                self.relation_vec.weight.data = normalize_emb(self.relation_vec.weight.data)\n",
    "                self.concept_vec.weight.data[:, :-1] = normalize_emb(self.concept_vec.weight.data[:, :-1])\n",
    "                self.concept_vec.weight.data[:, -1] = normalize_radius(self.concept_vec.weight.data[:, -1])\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                for k in range(batchSize):\n",
    "                    i = random.randint(0, self.D.trainSize - 1)\n",
    "                    if i < len(self.D.fb_r):\n",
    "                        cut = 1 - epoch * self.args[\"hrt_cut\"] / nepoch\n",
    "                        pairs[0].append(self.trainHLR(i, cut))\n",
    "                    elif i < len(self.D.fb_r) + len(self.D.instanceOf):\n",
    "                        cut = 1 - epoch * self.args[\"ins_cut\"] / nepoch\n",
    "                        pairs[1].append(self.trainInstanceOf(i, cut))\n",
    "                    else:\n",
    "                        cut = 1 - epoch * self.args[\"sub_cut\"] / nepoch\n",
    "                        pairs[2].append(self.trainSubClassOf(i, cut))\n",
    "\n",
    "                # for k in range(batchSize):\n",
    "                #     line = self.training_instance_file.readline()\n",
    "                #     line = line.strip().split(\"\\t\")\n",
    "                #     instance = [int(x) for x in line]\n",
    "                #     # print(instance)\n",
    "                #     if instance[0] == -1:\n",
    "                #         pairs[0].append(instance[1:])\n",
    "                #     if instance[0] == -2:\n",
    "                #         pairs[1].append(instance[1:])\n",
    "                #     if instance[0] == -3:\n",
    "                #         pairs[2].append(instance[1:])\n",
    "                # allreadyindex += batchSize\n",
    "\n",
    "                tensor_pairs= []\n",
    "                for i in range(3):\n",
    "                    tensor_pairs.append(torch.stack([torch.tensor(x) for x in list(zip(*pairs[i]))]))\n",
    "                loss1,dis_a,dis_b = self.doTrainHLR(tensor_pairs[0])\n",
    "                loss2 = self.doTrainInstanceOf(tensor_pairs[1])\n",
    "                loss3 = self.doTrainSubClassOf(tensor_pairs[2])\n",
    "                losses = loss1 + loss2 + loss3\n",
    "                losses.backward()\n",
    "\n",
    "                dis_a_L.append(torch.sqrt(dis_a).sum()), dis_b_L.append(torch.sqrt(dis_b).sum()) # for logs\n",
    "                dis_count += dis_a.size(0)\n",
    "\n",
    "                self.optimizer.step()\n",
    "                res += losses.detach().cpu().numpy()\n",
    "\n",
    "            print(sum(dis_a_L) / dis_count, sum(dis_b_L) / dis_count, dis_a.size())\n",
    "            dis_a_L, dis_b_L = [], []\n",
    "            dis_count = 0\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                print(\"epoch:{} Res: {:.6f} Loss {:.6f},loss1: {:.6f},loss2: {:.6f},loss3 {:.6f}\".format(epoch,res,losses,loss1,loss2,loss3))\n",
    "            if epoch % 500 == 0 or epoch == nepoch - 1:\n",
    "                entity_vec_save = self.entity_vec.weight.detach().cpu().numpy()\n",
    "                concept_vec_save = self.concept_vec.weight.detach().cpu().numpy()\n",
    "                relation_vec_save = self.relation_vec.weight.detach().cpu().numpy()\n",
    "\n",
    "                # with open(\"embeddings/transc/\"+self.args.version+\"_embeddings_epoch\" + str(epoch) + \".pkl\", 'wb') as file:\n",
    "                #    pkl.dump({\"entity_vec\": entity_vec_save,\n",
    "                #             \"concept_vec\": concept_vec_save,\n",
    "                #             \"relation_vec\":relation_vec_save},file)\n",
    "                #print(\"saved!\")\n",
    "\n",
    "                #write for cpp test\n",
    "                with open(\"vector/\"+self.args[\"dataset\"] +\"/entity2vec.vec\", 'w') as file:\n",
    "                    for vec in entity_vec_save:\n",
    "                        list_vec = list(vec)\n",
    "                        str_vec = \"\\t\".join([str(x) for x in list_vec])\n",
    "                        file.write(str_vec+\"\\n\")\n",
    "\n",
    "                with open(\"vector/\"+ self.args[\"dataset\"] + \"/relation2vec.vec\", 'w') as file:\n",
    "                    for vec in relation_vec_save:\n",
    "                        list_vec = list(vec)\n",
    "                        str_vec = \"\\t\".join([str(x) for x in list_vec])\n",
    "                        file.write(str_vec+\"\\n\")\n",
    "\n",
    "                with open(\"vector/\" + self.args[\"dataset\"]+\"/concept2vec.vec\", 'w') as file:\n",
    "                    for vec in concept_vec_save:\n",
    "                        list_vec = list(vec)\n",
    "                        str_vec = \"\\t\".join([str(x) for x in list_vec[:-1]])\n",
    "                        file.write(str_vec + \"\\n\" + str(list_vec[-1]) + \"\\n\")\n",
    "        # self.training_instance_file.close()\n",
    "\n",
    "\n",
    "    def trainHLR(self, i, cut):\n",
    "        pr = 0.5\n",
    "        cur_fbr, cur_fbh, cur_fbt = self.D.fb_r[i], self.D.fb_h[i], self.D.fb_t[i]\n",
    "        if self.args[\"bern\"] == 1:\n",
    "            pr = float(self.D.right_num[cur_fbr]) / (self.D.right_num[cur_fbr] + self.D.left_num[cur_fbr])\n",
    "        if random.uniform(0, 1) < pr:\n",
    "            loop=True\n",
    "            while loop:\n",
    "\n",
    "                if len(self.D.instance_brother[cur_fbt]) > 0:\n",
    "                    if random.uniform(0, 1) < cut:\n",
    "                        j = random.randint(0, self.D.entity_num - 1)\n",
    "                    else:\n",
    "                        j = random.randint(0, len(self.D.instance_brother[cur_fbt]) - 1)\n",
    "                        j = self.D.instance_brother[cur_fbt][j]\n",
    "                else:\n",
    "                    j = random.randint(0, self.D.entity_num - 1)\n",
    "                loop = j in self.D.ok[(cur_fbh, cur_fbr)]\n",
    "            return cur_fbh, cur_fbt, cur_fbr, cur_fbh, j, cur_fbr\n",
    "        else:\n",
    "            loop=True\n",
    "            while loop:\n",
    "                if len(self.D.instance_brother[cur_fbh]) > 0:\n",
    "                    if random.uniform(0, 1) < cut:\n",
    "                        j = random.randint(0, self.D.entity_num - 1)\n",
    "                    else:\n",
    "                        j = random.randint(0, len(self.D.instance_brother[cur_fbh]) - 1)\n",
    "                        j = self.D.instance_brother[cur_fbh][j]\n",
    "                else:\n",
    "                    j = random.randint(0, self.D.entity_num - 1)\n",
    "                loop = ((j,cur_fbr) in self.D.ok) and (cur_fbt in self.D.ok[(j, cur_fbr)])\n",
    "            return cur_fbh, cur_fbt, cur_fbr, j, cur_fbt, cur_fbr\n",
    "\n",
    "    def trainInstanceOf(self, i, cut):\n",
    "        i = i - len(self.D.fb_h)\n",
    "        cur_ins,cur_cpt = self.D.instanceOf[i]\n",
    "        if random.randint(0, 1) == 0:\n",
    "            loop=True\n",
    "            while loop:\n",
    "                if len(self.D.instance_brother[cur_ins]) > 0: #\n",
    "                    if random.uniform(0, 1) < cut:\n",
    "                        j = random.randint(0, self.D.entity_num - 1)\n",
    "                    else:\n",
    "                        j = random.randint(0, len(self.D.instance_brother[cur_ins]) - 1)\n",
    "                        j = self.D.instance_brother[cur_ins][j]\n",
    "                else:\n",
    "                    j = random.randint(0, self.D.entity_num - 1)\n",
    "                loop = (j, cur_cpt) in self.D.instanceOf_ok\n",
    "            return cur_ins, cur_cpt, j, cur_cpt\n",
    "\n",
    "        else:\n",
    "            loop=True\n",
    "            while loop:\n",
    "                if len(self.D.concept_brother[cur_cpt]) > 0: #\n",
    "                    if random.uniform(0, 1) < cut:\n",
    "                        j = random.randint(0, self.D.concept_num - 1)\n",
    "                    else:\n",
    "                        j = random.randint(0, len(self.D.concept_brother[cur_cpt]) - 1)\n",
    "                        j = self.D.concept_brother[cur_cpt][j]\n",
    "                else:\n",
    "                    j = random.randint(0, self.D.concept_num - 1)\n",
    "                loop = (cur_ins, j) in self.D.instanceOf_ok\n",
    "            return cur_ins, cur_cpt, cur_ins, j\n",
    "\n",
    "    def trainSubClassOf(self, i, cut):\n",
    "        i = i - len(self.D.fb_h) - len(self.D.instanceOf)\n",
    "\n",
    "        cur_cpth,cur_cptt=self.D.subClassOf[i]\n",
    "        if random.randint(0, 1) == 0:\n",
    "            loop=True\n",
    "            while loop:\n",
    "                if len(self.D.concept_brother[cur_cpth]) > 0: #\n",
    "                    if random.uniform(0, 1) < cut:\n",
    "                        j = random.randint(0, self.D.concept_num - 1)\n",
    "                    else:\n",
    "                        j = random.randint(0, len(self.D.concept_brother[cur_cpth]) - 1)\n",
    "                        j = self.D.concept_brother[cur_cpth][j]\n",
    "                else:\n",
    "                    j = random.randint(0, self.D.concept_num - 1)\n",
    "                loop = (j, cur_cptt) in self.D.subClassOf_ok\n",
    "            return cur_cpth, cur_cptt, j, cur_cptt\n",
    "        else:\n",
    "            loop=True\n",
    "            while loop:\n",
    "                if len(self.D.concept_brother[cur_cptt]) > 0: #\n",
    "                    if random.uniform(0, 1) < cut:\n",
    "                        j = random.randint(0, self.D.concept_num - 1)\n",
    "                    else:\n",
    "                        j = random.randint(0, len(self.D.concept_brother[cur_cptt]) - 1)\n",
    "                        j = self.D.concept_brother[cur_cptt][j]\n",
    "                else:\n",
    "                    j = random.randint(0, self.D.concept_num - 1)\n",
    "                loop = (cur_cpth, j) in self.D.subClassOf_ok\n",
    "            return cur_cpth, cur_cptt, cur_cpth, j\n",
    "\n",
    "    def doTrainHLR(self, ids):\n",
    "        entity_embs = self.entity_vec(ids[[0, 1, 3, 4], :])\n",
    "        relation_embs = self.relation_vec(ids[[2, 5], :])\n",
    "\n",
    "        dis_a = norm(entity_embs[0] + relation_embs[0] - entity_embs[1],pnorm=self.args[\"pnorm\"])\n",
    "        dis_b = norm(entity_embs[2] + relation_embs[1] - entity_embs[3],pnorm=self.args[\"pnorm\"])\n",
    "\n",
    "        loss = F.relu(dis_a + self.args[\"margin_hrt\"] - dis_b).sum()\n",
    "        return loss,dis_a,dis_b\n",
    "\n",
    "    def doTrainInstanceOf(self, ids):\n",
    "        entity_embs = self.entity_vec(ids[[0, 2], :])\n",
    "        concept_embs = self.concept_vec(ids[[1, 3], :])\n",
    "        radius = concept_embs[:, :, -1]\n",
    "        concept_embs = concept_embs[:, :, :-1]\n",
    "\n",
    "        if self.args[\"pnorm\"]==1:\n",
    "            dis = F.relu(norm(entity_embs - concept_embs,pnorm=self.args[\"pnorm\"]) - torch.abs(radius))\n",
    "        else:\n",
    "            dis = F.relu(norm(entity_embs - concept_embs,pnorm=self.args[\"pnorm\"]) - radius ** 2)\n",
    "\n",
    "        loss = F.relu(dis[0] + self.args[\"margin_ins\"] - dis[1]).sum()\n",
    "        return loss\n",
    "\n",
    "    def doTrainSubClassOf(self, ids):\n",
    "        concept_embs_a = self.concept_vec(ids[[0,2],:])\n",
    "        concept_embs_b = self.concept_vec(ids[[1, 3], :])\n",
    "        radius_a = concept_embs_a[:, :, -1]\n",
    "        radius_b = concept_embs_b[:, :, -1]\n",
    "\n",
    "        concept_embs_a = concept_embs_a[:, :, :-1]\n",
    "        concept_embs_b = concept_embs_b[:, :, :-1]\n",
    "\n",
    "        if self.args[\"pnorm\"]==1:\n",
    "            dis = F.relu(norm(concept_embs_a - concept_embs_b,pnorm=self.args[\"pnorm\"]) + torch.abs(radius_a) - torch.abs(radius_b))\n",
    "        else:\n",
    "            dis = F.relu(norm(concept_embs_a - concept_embs_b,pnorm=self.args[\"pnorm\"]) + radius_a ** 2 - radius_b ** 2)\n",
    "\n",
    "        loss = F.relu(dis[0] + self.args[\"margin_sub\"] - dis[1]).sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(dataset,filename,split = 'Train'):\n",
    "    with open(\"data/\" + dataset + \"/\" + split+\"/\"+filename + \".txt\") as file:\n",
    "        L = file.readlines()\n",
    "        num = int(L[0].strip())\n",
    "        contents = [[x for x in line.strip().split()] for line in L[1:]]\n",
    "    return num, contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_triples(dataset,filename,split = 'Train'):\n",
    "    with open(\"data/\" + dataset + \"/\" + split+\"/\"+filename + \".txt\") as file:\n",
    "        L = file.readlines()\n",
    "        num = int(L[0].strip())\n",
    "        contents = [[int(x) for x in line.strip().split()] for line in L[1:]]\n",
    "    return num, contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_biples(dataset, filename,split = 'Train'):\n",
    "    with open(\"data/\" + dataset + \"/\" + split+\"/\"+filename + \".txt\") as file:\n",
    "        L = file.readlines()\n",
    "        contents = [[int(x) for x in line.strip().split()] for line in L[1:]]\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parseargs():\n",
    "#     parsers = argparse.ArgumentParser()\n",
    "#     parsers.add_argument(\"--emb_dim\", type=int, default=100)\n",
    "#     parsers.add_argument(\"--margin_hrt\", type=float, default=1.0)\n",
    "#     parsers.add_argument(\"--margin_ins\", type=float, default=0.4)\n",
    "#     parsers.add_argument(\"--margin_sub\", type=float, default=0.3)\n",
    "#     parsers.add_argument(\"--hrt_cut\", type=float, default=0.8)\n",
    "#     parsers.add_argument(\"--ins_cut\", type=float, default=0.8)\n",
    "#     parsers.add_argument(\"--sub_cut\", type=float, default=0.8)\n",
    "\n",
    "#     parsers.add_argument(\"--nepoch\", type=float, default=1000)\n",
    "#     parsers.add_argument(\"--nbatches\", type=float, default=100)\n",
    "\n",
    "#     parsers.add_argument(\"--lr\", type=float, default=0.001)\n",
    "#     parsers.add_argument(\"--bern\", type=int, default=1)\n",
    "#     parsers.add_argument(\"--pnorm\", type=int, default=1)\n",
    "#     parsers.add_argument(\"--dataset\", type=str, default=\"YAGO39K\")\n",
    "#     parsers.add_argument(\"--split\", type=str, default=\"Train\")\n",
    "#     parsers.add_argument(\"--version\", type=str, default='tmp')\n",
    "\n",
    "#     args = parsers.parse_args()\n",
    "#     return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code was using console inputs with argparse. Changed it to work with jupyter cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(config=None):\n",
    "    if config is None:\n",
    "        config = {\n",
    "            \"emb_dim\": 100,\n",
    "            \"margin_hrt\": 1.0,\n",
    "            \"margin_ins\": 0.4,\n",
    "            \"margin_sub\": 0.3,\n",
    "            \"hrt_cut\": 0.8,\n",
    "            \"ins_cut\": 0.8,\n",
    "            \"sub_cut\": 0.8,\n",
    "            \"nepoch\": 1000,\n",
    "            \"nbatches\": 100,\n",
    "            \"lr\": 0.001,\n",
    "            \"bern\": 1,\n",
    "            \"pnorm\": 1,\n",
    "            \"dataset\": \"YAGO39K\",\n",
    "            \"split\": \"Train\",\n",
    "            \"version\": \"tmp\",\n",
    "        }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     args = parseargs()\n",
    "\n",
    "#     if not os.path.exists(\"data/\" + args.dataset + \"/\" + args.split + \"/processed.pkl\"):\n",
    "#         dataset = Dataset(args=args)\n",
    "#         dataset.setup()\n",
    "#         dataset.save()\n",
    "#     else:\n",
    "#         dataset = load_processed(dataset_name=args.dataset, split=args.split)\n",
    "#         print(\"dataset loaded\")\n",
    "\n",
    "#     train = Train(args = args,dataset= dataset).cuda()\n",
    "#     train.doTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(config=None):\n",
    "#     if config is None:\n",
    "#         config = parse_args()\n",
    "\n",
    "#     if not os.path.exists(\"data/\" + config[\"dataset\"] + \"/\" + config[\"split\"] + \"/processed.pkl\"):\n",
    "#         dataset = Dataset(args=config)\n",
    "#         dataset.setup()\n",
    "#         dataset.save()\n",
    "#     else:\n",
    "#         dataset = load_processed(dataset_name=config[\"dataset\"], split=config[\"split\"])\n",
    "#         print(\"dataset loaded\")\n",
    "\n",
    "#     train = Train(args=config, dataset=dataset)\n",
    "#     train.doTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = parse_args()\n",
    "# dataset = Dataset(args=config)\n",
    "# dataset.setup()\n",
    "# dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was running out of RAM and had to change he main() function. Manually did the dataset.setup() and .save(). This produced 1.4GB file. On the run just told it to load the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded\n",
      "tensor(2.2661, grad_fn=<DivBackward0>) tensor(2.4240, grad_fn=<DivBackward0>) torch.Size([3553])\n",
      "epoch:0 Res: 315409.043457 Loss 2198.013428,loss1: 1074.718994,loss2: 1037.301270,loss3 85.993065\n",
      "tensor(2.2509, grad_fn=<DivBackward0>) tensor(2.5157, grad_fn=<DivBackward0>) torch.Size([3563])\n",
      "epoch:1 Res: 183869.618896 Loss 1682.000732,loss1: 845.824219,loss2: 779.106689,loss3 57.069775\n",
      "tensor(2.2224, grad_fn=<DivBackward0>) tensor(2.5391, grad_fn=<DivBackward0>) torch.Size([3568])\n",
      "epoch:2 Res: 145664.967041 Loss 1326.286621,loss1: 696.867188,loss2: 578.014404,loss3 51.404991\n",
      "tensor(2.1962, grad_fn=<DivBackward0>) tensor(2.5455, grad_fn=<DivBackward0>) torch.Size([3504])\n",
      "epoch:3 Res: 127302.855957 Loss 1108.858154,loss1: 651.675903,loss2: 401.379028,loss3 55.803261\n",
      "tensor(2.1967, grad_fn=<DivBackward0>) tensor(2.5667, grad_fn=<DivBackward0>) torch.Size([3539])\n",
      "epoch:4 Res: 116219.525024 Loss 1056.185791,loss1: 612.127747,loss2: 402.975677,loss3 41.082432\n",
      "tensor(2.1880, grad_fn=<DivBackward0>) tensor(2.5756, grad_fn=<DivBackward0>) torch.Size([3509])\n",
      "epoch:5 Res: 107598.499939 Loss 1081.547119,loss1: 582.756042,loss2: 455.470459,loss3 43.320618\n",
      "tensor(2.1803, grad_fn=<DivBackward0>) tensor(2.5818, grad_fn=<DivBackward0>) torch.Size([3572])\n",
      "epoch:6 Res: 98317.405823 Loss 1013.130066,loss1: 590.286316,loss2: 376.822113,loss3 46.021683\n",
      "tensor(2.1642, grad_fn=<DivBackward0>) tensor(2.5805, grad_fn=<DivBackward0>) torch.Size([3587])\n",
      "epoch:7 Res: 94227.119751 Loss 935.336792,loss1: 619.353821,loss2: 273.504089,loss3 42.478886\n",
      "tensor(2.1413, grad_fn=<DivBackward0>) tensor(2.5698, grad_fn=<DivBackward0>) torch.Size([3495])\n",
      "epoch:8 Res: 90403.765442 Loss 938.690063,loss1: 559.243347,loss2: 341.603455,loss3 37.843235\n",
      "tensor(2.1243, grad_fn=<DivBackward0>) tensor(2.5630, grad_fn=<DivBackward0>) torch.Size([3540])\n",
      "epoch:9 Res: 81666.981934 Loss 783.637573,loss1: 580.727295,loss2: 181.223297,loss3 21.687000\n",
      "tensor(2.1014, grad_fn=<DivBackward0>) tensor(2.5476, grad_fn=<DivBackward0>) torch.Size([3502])\n",
      "epoch:10 Res: 74112.243958 Loss 677.364929,loss1: 532.317383,loss2: 118.805664,loss3 26.241861\n",
      "tensor(2.0796, grad_fn=<DivBackward0>) tensor(2.5354, grad_fn=<DivBackward0>) torch.Size([3580])\n",
      "epoch:11 Res: 68476.632446 Loss 617.979004,loss1: 485.067810,loss2: 98.319405,loss3 34.591778\n",
      "tensor(2.0613, grad_fn=<DivBackward0>) tensor(2.5246, grad_fn=<DivBackward0>) torch.Size([3559])\n",
      "epoch:12 Res: 65457.877502 Loss 616.350647,loss1: 482.643036,loss2: 96.909454,loss3 36.798157\n",
      "tensor(2.0446, grad_fn=<DivBackward0>) tensor(2.5131, grad_fn=<DivBackward0>) torch.Size([3570])\n",
      "epoch:13 Res: 61166.035645 Loss 533.937195,loss1: 414.544739,loss2: 84.567909,loss3 34.824532\n",
      "tensor(2.0174, grad_fn=<DivBackward0>) tensor(2.4975, grad_fn=<DivBackward0>) torch.Size([3567])\n",
      "epoch:14 Res: 52935.814606 Loss 489.658783,loss1: 393.326660,loss2: 68.777077,loss3 27.555061\n",
      "tensor(2.0037, grad_fn=<DivBackward0>) tensor(2.4906, grad_fn=<DivBackward0>) torch.Size([3590])\n",
      "epoch:15 Res: 50838.986847 Loss 500.602966,loss1: 405.921112,loss2: 73.747154,loss3 20.934692\n",
      "tensor(1.9981, grad_fn=<DivBackward0>) tensor(2.4860, grad_fn=<DivBackward0>) torch.Size([3433])\n",
      "epoch:16 Res: 48024.753906 Loss 437.545013,loss1: 341.556030,loss2: 65.324493,loss3 30.664490\n",
      "tensor(1.9923, grad_fn=<DivBackward0>) tensor(2.4850, grad_fn=<DivBackward0>) torch.Size([3600])\n",
      "epoch:17 Res: 46168.914154 Loss 460.869690,loss1: 374.956543,loss2: 62.925617,loss3 22.987520\n",
      "tensor(1.9856, grad_fn=<DivBackward0>) tensor(2.4825, grad_fn=<DivBackward0>) torch.Size([3556])\n",
      "epoch:18 Res: 43577.974182 Loss 427.944641,loss1: 352.597961,loss2: 53.904228,loss3 21.442453\n",
      "tensor(1.9778, grad_fn=<DivBackward0>) tensor(2.4770, grad_fn=<DivBackward0>) torch.Size([3517])\n",
      "epoch:19 Res: 41327.623322 Loss 381.655945,loss1: 296.135620,loss2: 61.202724,loss3 24.317610\n",
      "tensor(1.9843, grad_fn=<DivBackward0>) tensor(2.4854, grad_fn=<DivBackward0>) torch.Size([3498])\n",
      "epoch:20 Res: 39980.596832 Loss 407.703064,loss1: 338.781342,loss2: 47.961731,loss3 20.959984\n",
      "tensor(1.9757, grad_fn=<DivBackward0>) tensor(2.4805, grad_fn=<DivBackward0>) torch.Size([3582])\n",
      "epoch:21 Res: 37910.681274 Loss 388.630951,loss1: 316.529541,loss2: 54.426670,loss3 17.674742\n",
      "tensor(1.9733, grad_fn=<DivBackward0>) tensor(2.4811, grad_fn=<DivBackward0>) torch.Size([3560])\n",
      "epoch:22 Res: 35893.515533 Loss 348.139343,loss1: 270.385834,loss2: 58.398956,loss3 19.354544\n",
      "tensor(1.9758, grad_fn=<DivBackward0>) tensor(2.4847, grad_fn=<DivBackward0>) torch.Size([3585])\n",
      "epoch:23 Res: 34929.716644 Loss 355.437408,loss1: 287.323547,loss2: 53.238422,loss3 14.875440\n",
      "tensor(1.9693, grad_fn=<DivBackward0>) tensor(2.4821, grad_fn=<DivBackward0>) torch.Size([3479])\n",
      "epoch:24 Res: 33150.884216 Loss 326.081055,loss1: 258.906097,loss2: 48.629620,loss3 18.545349\n",
      "tensor(1.9663, grad_fn=<DivBackward0>) tensor(2.4814, grad_fn=<DivBackward0>) torch.Size([3473])\n",
      "epoch:25 Res: 31650.003021 Loss 280.920929,loss1: 213.755798,loss2: 52.179230,loss3 14.985907\n",
      "tensor(1.9582, grad_fn=<DivBackward0>) tensor(2.4769, grad_fn=<DivBackward0>) torch.Size([3518])\n",
      "epoch:26 Res: 30566.722626 Loss 279.008484,loss1: 220.800934,loss2: 35.989498,loss3 22.218040\n",
      "tensor(1.9584, grad_fn=<DivBackward0>) tensor(2.4804, grad_fn=<DivBackward0>) torch.Size([3571])\n",
      "epoch:27 Res: 28887.203690 Loss 278.405273,loss1: 214.875229,loss2: 42.863708,loss3 20.666317\n",
      "tensor(1.9524, grad_fn=<DivBackward0>) tensor(2.4769, grad_fn=<DivBackward0>) torch.Size([3568])\n",
      "epoch:28 Res: 27721.084732 Loss 280.754395,loss1: 226.837830,loss2: 39.685425,loss3 14.231146\n",
      "tensor(1.9567, grad_fn=<DivBackward0>) tensor(2.4819, grad_fn=<DivBackward0>) torch.Size([3583])\n",
      "epoch:29 Res: 26748.915787 Loss 240.993088,loss1: 190.910599,loss2: 34.980049,loss3 15.102439\n",
      "tensor(1.9550, grad_fn=<DivBackward0>) tensor(2.4840, grad_fn=<DivBackward0>) torch.Size([3501])\n",
      "epoch:30 Res: 25379.566086 Loss 228.703308,loss1: 173.315186,loss2: 39.356449,loss3 16.031679\n",
      "tensor(1.9388, grad_fn=<DivBackward0>) tensor(2.4740, grad_fn=<DivBackward0>) torch.Size([3544])\n",
      "epoch:31 Res: 23497.839600 Loss 227.493698,loss1: 179.658356,loss2: 34.367287,loss3 13.468070\n",
      "tensor(1.9415, grad_fn=<DivBackward0>) tensor(2.4779, grad_fn=<DivBackward0>) torch.Size([3520])\n",
      "epoch:32 Res: 23201.631287 Loss 238.247009,loss1: 190.288574,loss2: 33.711746,loss3 14.246683\n",
      "tensor(1.9426, grad_fn=<DivBackward0>) tensor(2.4817, grad_fn=<DivBackward0>) torch.Size([3522])\n",
      "epoch:33 Res: 21705.779099 Loss 199.522675,loss1: 147.378021,loss2: 38.772022,loss3 13.372643\n",
      "tensor(1.9233, grad_fn=<DivBackward0>) tensor(2.4678, grad_fn=<DivBackward0>) torch.Size([3482])\n",
      "epoch:34 Res: 20272.319229 Loss 192.471390,loss1: 149.466583,loss2: 31.959011,loss3 11.045795\n",
      "tensor(1.9384, grad_fn=<DivBackward0>) tensor(2.4812, grad_fn=<DivBackward0>) torch.Size([3497])\n",
      "epoch:35 Res: 20180.638092 Loss 177.173874,loss1: 130.370132,loss2: 35.639717,loss3 11.164010\n",
      "tensor(1.9366, grad_fn=<DivBackward0>) tensor(2.4820, grad_fn=<DivBackward0>) torch.Size([3588])\n",
      "epoch:36 Res: 19116.540283 Loss 219.304230,loss1: 174.946091,loss2: 36.117451,loss3 8.240686\n",
      "tensor(1.9290, grad_fn=<DivBackward0>) tensor(2.4767, grad_fn=<DivBackward0>) torch.Size([3606])\n",
      "epoch:37 Res: 18299.747620 Loss 170.179810,loss1: 133.544098,loss2: 26.412741,loss3 10.222979\n",
      "tensor(1.9233, grad_fn=<DivBackward0>) tensor(2.4754, grad_fn=<DivBackward0>) torch.Size([3556])\n",
      "epoch:38 Res: 16997.941452 Loss 170.643585,loss1: 128.427368,loss2: 35.261963,loss3 6.954251\n",
      "tensor(1.9363, grad_fn=<DivBackward0>) tensor(2.4851, grad_fn=<DivBackward0>) torch.Size([3511])\n",
      "epoch:39 Res: 16757.954163 Loss 171.708008,loss1: 123.410797,loss2: 40.459362,loss3 7.837840\n",
      "tensor(1.9336, grad_fn=<DivBackward0>) tensor(2.4846, grad_fn=<DivBackward0>) torch.Size([3535])\n",
      "epoch:40 Res: 16455.452637 Loss 165.288437,loss1: 127.566917,loss2: 29.305149,loss3 8.416373\n",
      "tensor(1.9366, grad_fn=<DivBackward0>) tensor(2.4875, grad_fn=<DivBackward0>) torch.Size([3563])\n",
      "epoch:41 Res: 16144.196701 Loss 144.788849,loss1: 108.149048,loss2: 29.753050,loss3 6.886746\n",
      "tensor(1.9344, grad_fn=<DivBackward0>) tensor(2.4860, grad_fn=<DivBackward0>) torch.Size([3567])\n",
      "epoch:42 Res: 15358.320442 Loss 146.838730,loss1: 109.822426,loss2: 30.153980,loss3 6.862314\n",
      "tensor(1.9314, grad_fn=<DivBackward0>) tensor(2.4868, grad_fn=<DivBackward0>) torch.Size([3433])\n",
      "epoch:43 Res: 14632.880676 Loss 125.855042,loss1: 87.807213,loss2: 29.226814,loss3 8.821011\n",
      "tensor(1.9327, grad_fn=<DivBackward0>) tensor(2.4893, grad_fn=<DivBackward0>) torch.Size([3545])\n",
      "epoch:44 Res: 14275.588615 Loss 138.273926,loss1: 99.983040,loss2: 27.551197,loss3 10.739689\n",
      "tensor(1.9334, grad_fn=<DivBackward0>) tensor(2.4911, grad_fn=<DivBackward0>) torch.Size([3602])\n",
      "epoch:45 Res: 13650.916481 Loss 137.186600,loss1: 104.239822,loss2: 22.121651,loss3 10.825121\n",
      "tensor(1.9314, grad_fn=<DivBackward0>) tensor(2.4913, grad_fn=<DivBackward0>) torch.Size([3577])\n",
      "epoch:46 Res: 13415.775093 Loss 137.315674,loss1: 103.918427,loss2: 28.821856,loss3 4.575401\n",
      "tensor(1.9350, grad_fn=<DivBackward0>) tensor(2.4929, grad_fn=<DivBackward0>) torch.Size([3577])\n",
      "epoch:47 Res: 13147.354378 Loss 133.121017,loss1: 104.841827,loss2: 20.846581,loss3 7.432615\n",
      "tensor(1.9367, grad_fn=<DivBackward0>) tensor(2.4967, grad_fn=<DivBackward0>) torch.Size([3540])\n",
      "epoch:48 Res: 12709.115646 Loss 128.356445,loss1: 95.540413,loss2: 28.444805,loss3 4.371233\n",
      "tensor(1.9330, grad_fn=<DivBackward0>) tensor(2.4936, grad_fn=<DivBackward0>) torch.Size([3571])\n",
      "epoch:49 Res: 12634.434608 Loss 111.451347,loss1: 80.857590,loss2: 22.003853,loss3 8.589905\n",
      "tensor(1.9383, grad_fn=<DivBackward0>) tensor(2.4981, grad_fn=<DivBackward0>) torch.Size([3542])\n",
      "epoch:50 Res: 12388.913414 Loss 131.747986,loss1: 98.112541,loss2: 27.354397,loss3 6.281055\n",
      "tensor(1.9442, grad_fn=<DivBackward0>) tensor(2.5035, grad_fn=<DivBackward0>) torch.Size([3546])\n",
      "epoch:51 Res: 12132.162102 Loss 117.612144,loss1: 86.089645,loss2: 27.999815,loss3 3.522680\n",
      "tensor(1.9444, grad_fn=<DivBackward0>) tensor(2.5059, grad_fn=<DivBackward0>) torch.Size([3542])\n",
      "epoch:52 Res: 11789.658897 Loss 113.498451,loss1: 79.583481,loss2: 25.917437,loss3 7.997538\n",
      "tensor(1.9454, grad_fn=<DivBackward0>) tensor(2.5075, grad_fn=<DivBackward0>) torch.Size([3513])\n",
      "epoch:53 Res: 11350.999138 Loss 118.378014,loss1: 88.974358,loss2: 25.419811,loss3 3.983850\n",
      "tensor(1.9513, grad_fn=<DivBackward0>) tensor(2.5119, grad_fn=<DivBackward0>) torch.Size([3508])\n",
      "epoch:54 Res: 11127.781120 Loss 95.698235,loss1: 65.648735,loss2: 22.120861,loss3 7.928643\n",
      "tensor(1.9495, grad_fn=<DivBackward0>) tensor(2.5109, grad_fn=<DivBackward0>) torch.Size([3497])\n",
      "epoch:55 Res: 11107.308189 Loss 105.714584,loss1: 73.337547,loss2: 25.289930,loss3 7.087109\n",
      "tensor(1.9518, grad_fn=<DivBackward0>) tensor(2.5130, grad_fn=<DivBackward0>) torch.Size([3608])\n",
      "epoch:56 Res: 10763.662552 Loss 106.566193,loss1: 74.030029,loss2: 23.829584,loss3 8.706583\n",
      "tensor(1.9559, grad_fn=<DivBackward0>) tensor(2.5156, grad_fn=<DivBackward0>) torch.Size([3548])\n",
      "epoch:57 Res: 10660.723793 Loss 113.550697,loss1: 79.433907,loss2: 27.217335,loss3 6.899449\n",
      "tensor(1.9588, grad_fn=<DivBackward0>) tensor(2.5188, grad_fn=<DivBackward0>) torch.Size([3533])\n",
      "epoch:58 Res: 10483.199120 Loss 89.190689,loss1: 63.472595,loss2: 20.882524,loss3 4.835567\n",
      "tensor(1.9605, grad_fn=<DivBackward0>) tensor(2.5207, grad_fn=<DivBackward0>) torch.Size([3580])\n",
      "epoch:59 Res: 10152.651520 Loss 99.141861,loss1: 75.526276,loss2: 21.310696,loss3 2.304884\n",
      "tensor(1.9632, grad_fn=<DivBackward0>) tensor(2.5246, grad_fn=<DivBackward0>) torch.Size([3510])\n",
      "epoch:60 Res: 10119.489662 Loss 99.667587,loss1: 73.436729,loss2: 22.926058,loss3 3.304801\n",
      "tensor(1.9667, grad_fn=<DivBackward0>) tensor(2.5278, grad_fn=<DivBackward0>) torch.Size([3541])\n",
      "epoch:61 Res: 9895.784988 Loss 110.325737,loss1: 84.978432,loss2: 21.838894,loss3 3.508416\n",
      "tensor(1.9680, grad_fn=<DivBackward0>) tensor(2.5283, grad_fn=<DivBackward0>) torch.Size([3591])\n",
      "epoch:62 Res: 9921.369255 Loss 93.259796,loss1: 71.033463,loss2: 19.322361,loss3 2.903974\n",
      "tensor(1.9674, grad_fn=<DivBackward0>) tensor(2.5281, grad_fn=<DivBackward0>) torch.Size([3498])\n",
      "epoch:63 Res: 9626.488884 Loss 87.646339,loss1: 62.282478,loss2: 22.208410,loss3 3.155450\n",
      "tensor(1.9692, grad_fn=<DivBackward0>) tensor(2.5307, grad_fn=<DivBackward0>) torch.Size([3553])\n",
      "epoch:64 Res: 9488.726234 Loss 98.686043,loss1: 75.226028,loss2: 18.180895,loss3 5.279124\n",
      "tensor(1.9730, grad_fn=<DivBackward0>) tensor(2.5333, grad_fn=<DivBackward0>) torch.Size([3533])\n",
      "epoch:65 Res: 9554.144234 Loss 98.538383,loss1: 71.226395,loss2: 24.256641,loss3 3.055354\n",
      "tensor(1.9769, grad_fn=<DivBackward0>) tensor(2.5376, grad_fn=<DivBackward0>) torch.Size([3564])\n",
      "epoch:66 Res: 9395.632423 Loss 79.833061,loss1: 57.591667,loss2: 17.998783,loss3 4.242609\n",
      "tensor(1.9799, grad_fn=<DivBackward0>) tensor(2.5403, grad_fn=<DivBackward0>) torch.Size([3576])\n",
      "epoch:67 Res: 9165.532600 Loss 95.006432,loss1: 66.256401,loss2: 26.467707,loss3 2.282323\n",
      "tensor(1.9800, grad_fn=<DivBackward0>) tensor(2.5408, grad_fn=<DivBackward0>) torch.Size([3440])\n",
      "epoch:68 Res: 9001.683357 Loss 95.738808,loss1: 69.570641,loss2: 21.736572,loss3 4.431597\n",
      "tensor(1.9841, grad_fn=<DivBackward0>) tensor(2.5440, grad_fn=<DivBackward0>) torch.Size([3502])\n",
      "epoch:69 Res: 8965.377724 Loss 92.892525,loss1: 70.205597,loss2: 18.318645,loss3 4.368277\n",
      "tensor(1.9903, grad_fn=<DivBackward0>) tensor(2.5491, grad_fn=<DivBackward0>) torch.Size([3477])\n",
      "epoch:70 Res: 8852.713524 Loss 95.452263,loss1: 67.522842,loss2: 24.858145,loss3 3.071270\n",
      "tensor(1.9924, grad_fn=<DivBackward0>) tensor(2.5503, grad_fn=<DivBackward0>) torch.Size([3524])\n",
      "epoch:71 Res: 8832.935555 Loss 69.245750,loss1: 50.939743,loss2: 14.538317,loss3 3.767695\n",
      "tensor(1.9928, grad_fn=<DivBackward0>) tensor(2.5530, grad_fn=<DivBackward0>) torch.Size([3573])\n",
      "epoch:72 Res: 8583.958549 Loss 84.880539,loss1: 58.747833,loss2: 22.287716,loss3 3.844987\n",
      "tensor(1.9919, grad_fn=<DivBackward0>) tensor(2.5512, grad_fn=<DivBackward0>) torch.Size([3519])\n",
      "epoch:73 Res: 8550.894402 Loss 72.981873,loss1: 54.731564,loss2: 13.688265,loss3 4.562043\n",
      "tensor(2.0009, grad_fn=<DivBackward0>) tensor(2.5588, grad_fn=<DivBackward0>) torch.Size([3501])\n",
      "epoch:74 Res: 8430.124939 Loss 87.356102,loss1: 61.584270,loss2: 21.247734,loss3 4.524100\n",
      "tensor(2.0049, grad_fn=<DivBackward0>) tensor(2.5614, grad_fn=<DivBackward0>) torch.Size([3552])\n",
      "epoch:75 Res: 8346.628517 Loss 79.351952,loss1: 58.240318,loss2: 19.635162,loss3 1.476470\n",
      "tensor(2.0007, grad_fn=<DivBackward0>) tensor(2.5592, grad_fn=<DivBackward0>) torch.Size([3587])\n",
      "epoch:76 Res: 8242.292160 Loss 80.052391,loss1: 57.221581,loss2: 19.192604,loss3 3.638210\n",
      "tensor(2.0006, grad_fn=<DivBackward0>) tensor(2.5616, grad_fn=<DivBackward0>) torch.Size([3524])\n",
      "epoch:77 Res: 8082.277542 Loss 93.142029,loss1: 64.874374,loss2: 24.207186,loss3 4.060469\n",
      "tensor(2.0062, grad_fn=<DivBackward0>) tensor(2.5642, grad_fn=<DivBackward0>) torch.Size([3589])\n",
      "epoch:78 Res: 8015.567467 Loss 82.172043,loss1: 63.445435,loss2: 16.764200,loss3 1.962408\n",
      "tensor(2.0047, grad_fn=<DivBackward0>) tensor(2.5631, grad_fn=<DivBackward0>) torch.Size([3549])\n",
      "epoch:79 Res: 7979.980934 Loss 84.240318,loss1: 67.723656,loss2: 14.391014,loss3 2.125649\n",
      "tensor(2.0083, grad_fn=<DivBackward0>) tensor(2.5676, grad_fn=<DivBackward0>) torch.Size([3562])\n",
      "epoch:80 Res: 7876.968876 Loss 83.588257,loss1: 62.556526,loss2: 16.466221,loss3 4.565504\n",
      "tensor(2.0139, grad_fn=<DivBackward0>) tensor(2.5721, grad_fn=<DivBackward0>) torch.Size([3626])\n",
      "epoch:81 Res: 7836.503040 Loss 70.382385,loss1: 50.698189,loss2: 16.999249,loss3 2.684951\n",
      "tensor(2.0148, grad_fn=<DivBackward0>) tensor(2.5730, grad_fn=<DivBackward0>) torch.Size([3541])\n",
      "epoch:82 Res: 7750.334976 Loss 68.660767,loss1: 49.118679,loss2: 17.461790,loss3 2.080297\n",
      "tensor(2.0130, grad_fn=<DivBackward0>) tensor(2.5717, grad_fn=<DivBackward0>) torch.Size([3529])\n",
      "epoch:83 Res: 7729.418800 Loss 74.766472,loss1: 55.119358,loss2: 17.388081,loss3 2.259031\n",
      "tensor(2.0196, grad_fn=<DivBackward0>) tensor(2.5757, grad_fn=<DivBackward0>) torch.Size([3530])\n",
      "epoch:84 Res: 7623.911938 Loss 75.097855,loss1: 53.654732,loss2: 19.468925,loss3 1.974196\n",
      "tensor(2.0190, grad_fn=<DivBackward0>) tensor(2.5758, grad_fn=<DivBackward0>) torch.Size([3516])\n",
      "epoch:85 Res: 7667.026051 Loss 78.575035,loss1: 56.310543,loss2: 18.459322,loss3 3.805171\n",
      "tensor(2.0208, grad_fn=<DivBackward0>) tensor(2.5796, grad_fn=<DivBackward0>) torch.Size([3508])\n",
      "epoch:86 Res: 7589.785480 Loss 81.161148,loss1: 66.369881,loss2: 12.624996,loss3 2.166273\n",
      "tensor(2.0278, grad_fn=<DivBackward0>) tensor(2.5844, grad_fn=<DivBackward0>) torch.Size([3606])\n",
      "epoch:87 Res: 7449.269741 Loss 57.425674,loss1: 37.273113,loss2: 17.573643,loss3 2.578917\n",
      "tensor(2.0294, grad_fn=<DivBackward0>) tensor(2.5874, grad_fn=<DivBackward0>) torch.Size([3603])\n",
      "epoch:88 Res: 7351.114143 Loss 69.612755,loss1: 53.154247,loss2: 15.524893,loss3 0.933617\n",
      "tensor(2.0250, grad_fn=<DivBackward0>) tensor(2.5814, grad_fn=<DivBackward0>) torch.Size([3561])\n",
      "epoch:89 Res: 7300.834064 Loss 64.057854,loss1: 46.712303,loss2: 15.737143,loss3 1.608409\n",
      "tensor(2.0284, grad_fn=<DivBackward0>) tensor(2.5850, grad_fn=<DivBackward0>) torch.Size([3575])\n",
      "epoch:90 Res: 7306.504841 Loss 81.898735,loss1: 62.286110,loss2: 17.641918,loss3 1.970713\n",
      "tensor(2.0326, grad_fn=<DivBackward0>) tensor(2.5899, grad_fn=<DivBackward0>) torch.Size([3491])\n",
      "epoch:91 Res: 7235.633831 Loss 70.617943,loss1: 51.791153,loss2: 15.943691,loss3 2.883093\n",
      "tensor(2.0355, grad_fn=<DivBackward0>) tensor(2.5919, grad_fn=<DivBackward0>) torch.Size([3585])\n",
      "epoch:92 Res: 7236.681492 Loss 77.520149,loss1: 57.498577,loss2: 17.769215,loss3 2.252361\n",
      "tensor(2.0368, grad_fn=<DivBackward0>) tensor(2.5936, grad_fn=<DivBackward0>) torch.Size([3588])\n",
      "epoch:93 Res: 7034.744999 Loss 75.094017,loss1: 55.960014,loss2: 17.130894,loss3 2.003107\n",
      "tensor(2.0338, grad_fn=<DivBackward0>) tensor(2.5913, grad_fn=<DivBackward0>) torch.Size([3601])\n",
      "epoch:94 Res: 6998.467049 Loss 78.407013,loss1: 59.572441,loss2: 16.005356,loss3 2.829215\n",
      "tensor(2.0339, grad_fn=<DivBackward0>) tensor(2.5914, grad_fn=<DivBackward0>) torch.Size([3546])\n",
      "epoch:95 Res: 6966.174007 Loss 68.045326,loss1: 51.900074,loss2: 14.842315,loss3 1.302937\n",
      "tensor(2.0386, grad_fn=<DivBackward0>) tensor(2.5953, grad_fn=<DivBackward0>) torch.Size([3519])\n",
      "epoch:96 Res: 6889.138214 Loss 67.217667,loss1: 51.914917,loss2: 14.183554,loss3 1.119193\n",
      "tensor(2.0391, grad_fn=<DivBackward0>) tensor(2.5946, grad_fn=<DivBackward0>) torch.Size([3534])\n",
      "epoch:97 Res: 6853.387444 Loss 60.106781,loss1: 42.495258,loss2: 14.097234,loss3 3.514289\n",
      "tensor(2.0400, grad_fn=<DivBackward0>) tensor(2.5978, grad_fn=<DivBackward0>) torch.Size([3566])\n",
      "epoch:98 Res: 6786.201004 Loss 68.075836,loss1: 48.959854,loss2: 16.969311,loss3 2.146665\n",
      "tensor(2.0413, grad_fn=<DivBackward0>) tensor(2.5982, grad_fn=<DivBackward0>) torch.Size([3488])\n",
      "epoch:99 Res: 6696.004280 Loss 58.812813,loss1: 45.666164,loss2: 11.299482,loss3 1.847166\n",
      "tensor(2.0409, grad_fn=<DivBackward0>) tensor(2.5975, grad_fn=<DivBackward0>) torch.Size([3537])\n",
      "epoch:100 Res: 6712.170925 Loss 61.754398,loss1: 46.215981,loss2: 13.639065,loss3 1.899352\n",
      "tensor(2.0435, grad_fn=<DivBackward0>) tensor(2.6007, grad_fn=<DivBackward0>) torch.Size([3533])\n",
      "epoch:101 Res: 6679.996548 Loss 78.759613,loss1: 60.698479,loss2: 14.917322,loss3 3.143811\n",
      "tensor(2.0482, grad_fn=<DivBackward0>) tensor(2.6047, grad_fn=<DivBackward0>) torch.Size([3508])\n",
      "epoch:102 Res: 6744.723141 Loss 61.955620,loss1: 46.407352,loss2: 14.450539,loss3 1.097729\n",
      "tensor(2.0483, grad_fn=<DivBackward0>) tensor(2.6047, grad_fn=<DivBackward0>) torch.Size([3507])\n",
      "epoch:103 Res: 6652.902962 Loss 66.330826,loss1: 50.045982,loss2: 14.377176,loss3 1.907668\n",
      "tensor(2.0493, grad_fn=<DivBackward0>) tensor(2.6053, grad_fn=<DivBackward0>) torch.Size([3591])\n",
      "epoch:104 Res: 6589.968281 Loss 59.793808,loss1: 43.094349,loss2: 13.883732,loss3 2.815729\n",
      "tensor(2.0534, grad_fn=<DivBackward0>) tensor(2.6089, grad_fn=<DivBackward0>) torch.Size([3639])\n",
      "epoch:105 Res: 6582.961147 Loss 68.607620,loss1: 51.320892,loss2: 15.759912,loss3 1.526818\n",
      "tensor(2.0572, grad_fn=<DivBackward0>) tensor(2.6116, grad_fn=<DivBackward0>) torch.Size([3518])\n",
      "epoch:106 Res: 6497.828903 Loss 74.828102,loss1: 56.283924,loss2: 17.156773,loss3 1.387404\n",
      "tensor(2.0577, grad_fn=<DivBackward0>) tensor(2.6117, grad_fn=<DivBackward0>) torch.Size([3542])\n",
      "epoch:107 Res: 6388.111897 Loss 66.319954,loss1: 48.856865,loss2: 15.009964,loss3 2.453128\n",
      "tensor(2.0579, grad_fn=<DivBackward0>) tensor(2.6125, grad_fn=<DivBackward0>) torch.Size([3485])\n",
      "epoch:108 Res: 6375.698292 Loss 62.100899,loss1: 45.959278,loss2: 14.973005,loss3 1.168617\n",
      "tensor(2.0603, grad_fn=<DivBackward0>) tensor(2.6146, grad_fn=<DivBackward0>) torch.Size([3562])\n",
      "epoch:109 Res: 6388.628330 Loss 58.855286,loss1: 43.234615,loss2: 13.692163,loss3 1.928506\n",
      "tensor(2.0600, grad_fn=<DivBackward0>) tensor(2.6150, grad_fn=<DivBackward0>) torch.Size([3614])\n",
      "epoch:110 Res: 6426.366119 Loss 61.375381,loss1: 46.642097,loss2: 12.930849,loss3 1.802436\n",
      "tensor(2.0623, grad_fn=<DivBackward0>) tensor(2.6165, grad_fn=<DivBackward0>) torch.Size([3578])\n",
      "epoch:111 Res: 6274.750580 Loss 55.617081,loss1: 40.568779,loss2: 13.542563,loss3 1.505737\n",
      "tensor(2.0670, grad_fn=<DivBackward0>) tensor(2.6206, grad_fn=<DivBackward0>) torch.Size([3587])\n",
      "epoch:112 Res: 6294.060665 Loss 63.205795,loss1: 45.356274,loss2: 14.892494,loss3 2.957026\n",
      "tensor(2.0669, grad_fn=<DivBackward0>) tensor(2.6216, grad_fn=<DivBackward0>) torch.Size([3598])\n",
      "epoch:113 Res: 6143.290058 Loss 71.438354,loss1: 53.771095,loss2: 14.500378,loss3 3.166884\n",
      "tensor(2.0701, grad_fn=<DivBackward0>) tensor(2.6238, grad_fn=<DivBackward0>) torch.Size([3557])\n",
      "epoch:114 Res: 6081.444363 Loss 55.318768,loss1: 41.879360,loss2: 11.755899,loss3 1.683506\n",
      "tensor(2.0674, grad_fn=<DivBackward0>) tensor(2.6228, grad_fn=<DivBackward0>) torch.Size([3622])\n",
      "epoch:115 Res: 6255.542614 Loss 68.821075,loss1: 50.044800,loss2: 17.091051,loss3 1.685224\n",
      "tensor(2.0692, grad_fn=<DivBackward0>) tensor(2.6250, grad_fn=<DivBackward0>) torch.Size([3569])\n",
      "epoch:116 Res: 6041.517910 Loss 55.293385,loss1: 38.570171,loss2: 15.057553,loss3 1.665659\n",
      "tensor(2.0719, grad_fn=<DivBackward0>) tensor(2.6236, grad_fn=<DivBackward0>) torch.Size([3554])\n",
      "epoch:117 Res: 6256.534138 Loss 63.318455,loss1: 47.898212,loss2: 14.907661,loss3 0.512579\n",
      "tensor(2.0741, grad_fn=<DivBackward0>) tensor(2.6283, grad_fn=<DivBackward0>) torch.Size([3618])\n",
      "epoch:118 Res: 6095.932884 Loss 67.745674,loss1: 50.453991,loss2: 15.344724,loss3 1.946959\n",
      "tensor(2.0750, grad_fn=<DivBackward0>) tensor(2.6278, grad_fn=<DivBackward0>) torch.Size([3482])\n",
      "epoch:119 Res: 5989.832703 Loss 46.919662,loss1: 35.328545,loss2: 10.699580,loss3 0.891538\n",
      "tensor(2.0772, grad_fn=<DivBackward0>) tensor(2.6333, grad_fn=<DivBackward0>) torch.Size([3584])\n",
      "epoch:120 Res: 6023.582893 Loss 58.660835,loss1: 45.610947,loss2: 11.240467,loss3 1.809420\n",
      "tensor(2.0792, grad_fn=<DivBackward0>) tensor(2.6343, grad_fn=<DivBackward0>) torch.Size([3484])\n",
      "epoch:121 Res: 5971.758217 Loss 43.614105,loss1: 32.176472,loss2: 10.181942,loss3 1.255690\n",
      "tensor(2.0840, grad_fn=<DivBackward0>) tensor(2.6380, grad_fn=<DivBackward0>) torch.Size([3568])\n",
      "epoch:122 Res: 5936.637188 Loss 54.923744,loss1: 39.275787,loss2: 15.413601,loss3 0.234356\n",
      "tensor(2.0826, grad_fn=<DivBackward0>) tensor(2.6366, grad_fn=<DivBackward0>) torch.Size([3555])\n",
      "epoch:123 Res: 5927.591831 Loss 57.405704,loss1: 40.904213,loss2: 15.526567,loss3 0.974925\n",
      "tensor(2.0791, grad_fn=<DivBackward0>) tensor(2.6338, grad_fn=<DivBackward0>) torch.Size([3506])\n",
      "epoch:124 Res: 5909.829906 Loss 58.438419,loss1: 40.381592,loss2: 16.586468,loss3 1.470359\n",
      "tensor(2.0834, grad_fn=<DivBackward0>) tensor(2.6375, grad_fn=<DivBackward0>) torch.Size([3538])\n",
      "epoch:125 Res: 5815.791431 Loss 48.119869,loss1: 35.395294,loss2: 10.953666,loss3 1.770910\n",
      "tensor(2.0841, grad_fn=<DivBackward0>) tensor(2.6385, grad_fn=<DivBackward0>) torch.Size([3488])\n",
      "epoch:126 Res: 5928.831459 Loss 58.708061,loss1: 41.469593,loss2: 15.144596,loss3 2.093873\n",
      "tensor(2.0883, grad_fn=<DivBackward0>) tensor(2.6413, grad_fn=<DivBackward0>) torch.Size([3645])\n",
      "epoch:127 Res: 5807.254562 Loss 49.953079,loss1: 35.267067,loss2: 12.642442,loss3 2.043573\n",
      "tensor(2.0942, grad_fn=<DivBackward0>) tensor(2.6463, grad_fn=<DivBackward0>) torch.Size([3556])\n",
      "epoch:128 Res: 5735.053051 Loss 58.381084,loss1: 40.900776,loss2: 16.133266,loss3 1.347041\n",
      "tensor(2.0982, grad_fn=<DivBackward0>) tensor(2.6495, grad_fn=<DivBackward0>) torch.Size([3521])\n",
      "epoch:129 Res: 5793.808182 Loss 42.786098,loss1: 29.030447,loss2: 12.369079,loss3 1.386572\n",
      "tensor(2.0945, grad_fn=<DivBackward0>) tensor(2.6471, grad_fn=<DivBackward0>) torch.Size([3532])\n",
      "epoch:130 Res: 5667.887527 Loss 51.743641,loss1: 36.898132,loss2: 12.753860,loss3 2.091646\n",
      "tensor(2.0920, grad_fn=<DivBackward0>) tensor(2.6448, grad_fn=<DivBackward0>) torch.Size([3595])\n",
      "epoch:131 Res: 5682.114109 Loss 53.862034,loss1: 41.145241,loss2: 10.705306,loss3 2.011488\n",
      "tensor(2.0965, grad_fn=<DivBackward0>) tensor(2.6489, grad_fn=<DivBackward0>) torch.Size([3535])\n",
      "epoch:132 Res: 5698.048264 Loss 50.962349,loss1: 34.573132,loss2: 15.211121,loss3 1.178096\n",
      "tensor(2.0976, grad_fn=<DivBackward0>) tensor(2.6483, grad_fn=<DivBackward0>) torch.Size([3469])\n",
      "epoch:133 Res: 5874.323860 Loss 64.675949,loss1: 49.420479,loss2: 14.698709,loss3 0.556760\n",
      "tensor(2.0962, grad_fn=<DivBackward0>) tensor(2.6488, grad_fn=<DivBackward0>) torch.Size([3553])\n",
      "epoch:134 Res: 5715.628712 Loss 54.897305,loss1: 42.292789,loss2: 11.454204,loss3 1.150312\n",
      "tensor(2.1024, grad_fn=<DivBackward0>) tensor(2.6566, grad_fn=<DivBackward0>) torch.Size([3570])\n",
      "epoch:135 Res: 5713.814491 Loss 51.481461,loss1: 39.436222,loss2: 11.310751,loss3 0.734491\n",
      "tensor(2.1033, grad_fn=<DivBackward0>) tensor(2.6540, grad_fn=<DivBackward0>) torch.Size([3542])\n",
      "epoch:136 Res: 5674.323433 Loss 55.372631,loss1: 40.578011,loss2: 12.916140,loss3 1.878483\n",
      "tensor(2.1003, grad_fn=<DivBackward0>) tensor(2.6526, grad_fn=<DivBackward0>) torch.Size([3490])\n",
      "epoch:137 Res: 5620.117535 Loss 53.441185,loss1: 37.249516,loss2: 14.605450,loss3 1.586220\n",
      "tensor(2.1044, grad_fn=<DivBackward0>) tensor(2.6560, grad_fn=<DivBackward0>) torch.Size([3611])\n",
      "epoch:138 Res: 5576.179676 Loss 57.115387,loss1: 45.763214,loss2: 9.961367,loss3 1.390807\n",
      "tensor(2.1057, grad_fn=<DivBackward0>) tensor(2.6576, grad_fn=<DivBackward0>) torch.Size([3609])\n",
      "epoch:139 Res: 5490.575150 Loss 58.071640,loss1: 44.299583,loss2: 12.130119,loss3 1.641936\n",
      "tensor(2.1067, grad_fn=<DivBackward0>) tensor(2.6579, grad_fn=<DivBackward0>) torch.Size([3545])\n",
      "epoch:140 Res: 5500.559040 Loss 62.320591,loss1: 46.981457,loss2: 13.869494,loss3 1.469637\n",
      "tensor(2.1105, grad_fn=<DivBackward0>) tensor(2.6604, grad_fn=<DivBackward0>) torch.Size([3570])\n",
      "epoch:141 Res: 5501.501442 Loss 58.255695,loss1: 44.677841,loss2: 12.025110,loss3 1.552744\n",
      "tensor(2.1147, grad_fn=<DivBackward0>) tensor(2.6631, grad_fn=<DivBackward0>) torch.Size([3517])\n",
      "epoch:142 Res: 5539.981049 Loss 63.289261,loss1: 46.938103,loss2: 15.700796,loss3 0.650362\n",
      "tensor(2.1146, grad_fn=<DivBackward0>) tensor(2.6646, grad_fn=<DivBackward0>) torch.Size([3492])\n",
      "epoch:143 Res: 5447.068150 Loss 47.672382,loss1: 37.583237,loss2: 8.826683,loss3 1.262462\n",
      "tensor(2.1090, grad_fn=<DivBackward0>) tensor(2.6594, grad_fn=<DivBackward0>) torch.Size([3475])\n",
      "epoch:144 Res: 5374.200890 Loss 54.319530,loss1: 35.958038,loss2: 17.603117,loss3 0.758374\n",
      "tensor(2.1156, grad_fn=<DivBackward0>) tensor(2.6635, grad_fn=<DivBackward0>) torch.Size([3569])\n",
      "epoch:145 Res: 5528.280609 Loss 56.165844,loss1: 41.291885,loss2: 11.449825,loss3 3.424134\n",
      "tensor(2.1151, grad_fn=<DivBackward0>) tensor(2.6643, grad_fn=<DivBackward0>) torch.Size([3603])\n",
      "epoch:146 Res: 5509.696888 Loss 51.122852,loss1: 34.350376,loss2: 16.241653,loss3 0.530823\n",
      "tensor(2.1172, grad_fn=<DivBackward0>) tensor(2.6669, grad_fn=<DivBackward0>) torch.Size([3586])\n",
      "epoch:147 Res: 5264.516888 Loss 55.212116,loss1: 41.527355,loss2: 13.229877,loss3 0.454885\n",
      "tensor(2.1192, grad_fn=<DivBackward0>) tensor(2.6660, grad_fn=<DivBackward0>) torch.Size([3542])\n",
      "epoch:148 Res: 5386.797085 Loss 60.431404,loss1: 46.423985,loss2: 12.963713,loss3 1.043708\n",
      "tensor(2.1219, grad_fn=<DivBackward0>) tensor(2.6686, grad_fn=<DivBackward0>) torch.Size([3494])\n",
      "epoch:149 Res: 5407.644356 Loss 55.508560,loss1: 41.046059,loss2: 13.571432,loss3 0.891069\n",
      "tensor(2.1155, grad_fn=<DivBackward0>) tensor(2.6649, grad_fn=<DivBackward0>) torch.Size([3453])\n",
      "epoch:150 Res: 5360.342571 Loss 59.153561,loss1: 43.509247,loss2: 14.145132,loss3 1.499180\n",
      "tensor(2.1221, grad_fn=<DivBackward0>) tensor(2.6710, grad_fn=<DivBackward0>) torch.Size([3552])\n",
      "epoch:151 Res: 5411.683903 Loss 50.569279,loss1: 34.592926,loss2: 14.080235,loss3 1.896119\n",
      "tensor(2.1223, grad_fn=<DivBackward0>) tensor(2.6696, grad_fn=<DivBackward0>) torch.Size([3583])\n",
      "epoch:152 Res: 5386.856297 Loss 50.528076,loss1: 36.869465,loss2: 12.372422,loss3 1.286190\n",
      "tensor(2.1257, grad_fn=<DivBackward0>) tensor(2.6745, grad_fn=<DivBackward0>) torch.Size([3541])\n",
      "epoch:153 Res: 5226.432396 Loss 51.471138,loss1: 38.858097,loss2: 12.001282,loss3 0.611760\n",
      "tensor(2.1299, grad_fn=<DivBackward0>) tensor(2.6777, grad_fn=<DivBackward0>) torch.Size([3493])\n",
      "epoch:154 Res: 5240.069050 Loss 47.823746,loss1: 33.552017,loss2: 13.939260,loss3 0.332471\n",
      "tensor(2.1294, grad_fn=<DivBackward0>) tensor(2.6765, grad_fn=<DivBackward0>) torch.Size([3579])\n",
      "epoch:155 Res: 5214.153404 Loss 50.357647,loss1: 39.272533,loss2: 10.463866,loss3 0.621247\n",
      "tensor(2.1266, grad_fn=<DivBackward0>) tensor(2.6754, grad_fn=<DivBackward0>) torch.Size([3542])\n",
      "epoch:156 Res: 5292.685631 Loss 52.612724,loss1: 37.774895,loss2: 14.582606,loss3 0.255221\n",
      "tensor(2.1262, grad_fn=<DivBackward0>) tensor(2.6733, grad_fn=<DivBackward0>) torch.Size([3592])\n",
      "epoch:157 Res: 5287.730404 Loss 56.111877,loss1: 41.660240,loss2: 12.357196,loss3 2.094439\n",
      "tensor(2.1307, grad_fn=<DivBackward0>) tensor(2.6793, grad_fn=<DivBackward0>) torch.Size([3474])\n",
      "epoch:158 Res: 5148.423985 Loss 47.528084,loss1: 38.658005,loss2: 8.280342,loss3 0.589737\n",
      "tensor(2.1345, grad_fn=<DivBackward0>) tensor(2.6831, grad_fn=<DivBackward0>) torch.Size([3578])\n",
      "epoch:159 Res: 5167.890659 Loss 46.124161,loss1: 34.450623,loss2: 10.880340,loss3 0.793198\n",
      "tensor(2.1363, grad_fn=<DivBackward0>) tensor(2.6820, grad_fn=<DivBackward0>) torch.Size([3585])\n",
      "epoch:160 Res: 5145.907539 Loss 55.178738,loss1: 40.531189,loss2: 12.996958,loss3 1.650594\n",
      "tensor(2.1369, grad_fn=<DivBackward0>) tensor(2.6839, grad_fn=<DivBackward0>) torch.Size([3567])\n",
      "epoch:161 Res: 5109.168877 Loss 52.524071,loss1: 36.740185,loss2: 14.319264,loss3 1.464624\n",
      "tensor(2.1354, grad_fn=<DivBackward0>) tensor(2.6820, grad_fn=<DivBackward0>) torch.Size([3542])\n",
      "epoch:162 Res: 5146.737988 Loss 46.250546,loss1: 36.721085,loss2: 8.174041,loss3 1.355418\n",
      "tensor(2.1385, grad_fn=<DivBackward0>) tensor(2.6846, grad_fn=<DivBackward0>) torch.Size([3504])\n",
      "epoch:163 Res: 5067.714706 Loss 58.266800,loss1: 43.265343,loss2: 13.332908,loss3 1.668549\n",
      "tensor(2.1458, grad_fn=<DivBackward0>) tensor(2.6909, grad_fn=<DivBackward0>) torch.Size([3575])\n",
      "epoch:164 Res: 5183.969772 Loss 44.076199,loss1: 34.464165,loss2: 8.895936,loss3 0.716100\n",
      "tensor(2.1428, grad_fn=<DivBackward0>) tensor(2.6873, grad_fn=<DivBackward0>) torch.Size([3544])\n",
      "epoch:165 Res: 5085.426483 Loss 54.219067,loss1: 40.844070,loss2: 12.999529,loss3 0.375470\n",
      "tensor(2.1450, grad_fn=<DivBackward0>) tensor(2.6905, grad_fn=<DivBackward0>) torch.Size([3528])\n",
      "epoch:166 Res: 5103.079815 Loss 55.912182,loss1: 42.775242,loss2: 10.391713,loss3 2.745226\n",
      "tensor(2.1447, grad_fn=<DivBackward0>) tensor(2.6910, grad_fn=<DivBackward0>) torch.Size([3566])\n",
      "epoch:167 Res: 4927.178299 Loss 45.965981,loss1: 34.541702,loss2: 10.206446,loss3 1.217836\n",
      "tensor(2.1470, grad_fn=<DivBackward0>) tensor(2.6927, grad_fn=<DivBackward0>) torch.Size([3562])\n",
      "epoch:168 Res: 5058.776581 Loss 49.465584,loss1: 39.199718,loss2: 9.971724,loss3 0.294144\n",
      "tensor(2.1466, grad_fn=<DivBackward0>) tensor(2.6917, grad_fn=<DivBackward0>) torch.Size([3546])\n",
      "epoch:169 Res: 5027.316353 Loss 52.139687,loss1: 39.570469,loss2: 11.743030,loss3 0.826188\n",
      "tensor(2.1472, grad_fn=<DivBackward0>) tensor(2.6936, grad_fn=<DivBackward0>) torch.Size([3403])\n",
      "epoch:170 Res: 5004.230793 Loss 50.305984,loss1: 37.469128,loss2: 11.631568,loss3 1.205289\n",
      "tensor(2.1520, grad_fn=<DivBackward0>) tensor(2.6965, grad_fn=<DivBackward0>) torch.Size([3474])\n",
      "epoch:171 Res: 4928.073582 Loss 44.932720,loss1: 34.436096,loss2: 8.984579,loss3 1.512045\n",
      "tensor(2.1559, grad_fn=<DivBackward0>) tensor(2.6996, grad_fn=<DivBackward0>) torch.Size([3518])\n",
      "epoch:172 Res: 5057.824432 Loss 47.631607,loss1: 35.365440,loss2: 12.143112,loss3 0.123055\n",
      "tensor(2.1608, grad_fn=<DivBackward0>) tensor(2.7031, grad_fn=<DivBackward0>) torch.Size([3563])\n",
      "epoch:173 Res: 4917.921001 Loss 57.778534,loss1: 45.874275,loss2: 9.184519,loss3 2.719743\n",
      "tensor(2.1619, grad_fn=<DivBackward0>) tensor(2.7030, grad_fn=<DivBackward0>) torch.Size([3547])\n",
      "epoch:174 Res: 4981.214397 Loss 55.395458,loss1: 43.412598,loss2: 11.291591,loss3 0.691268\n",
      "tensor(2.1631, grad_fn=<DivBackward0>) tensor(2.7039, grad_fn=<DivBackward0>) torch.Size([3497])\n",
      "epoch:175 Res: 4900.306648 Loss 52.413414,loss1: 38.401001,loss2: 12.172972,loss3 1.839439\n",
      "tensor(2.1620, grad_fn=<DivBackward0>) tensor(2.7054, grad_fn=<DivBackward0>) torch.Size([3471])\n",
      "epoch:176 Res: 4826.165230 Loss 51.857101,loss1: 40.239780,loss2: 10.451483,loss3 1.165840\n",
      "tensor(2.1672, grad_fn=<DivBackward0>) tensor(2.7083, grad_fn=<DivBackward0>) torch.Size([3508])\n",
      "epoch:177 Res: 4765.613251 Loss 46.412342,loss1: 34.141125,loss2: 11.454298,loss3 0.816920\n",
      "tensor(2.1637, grad_fn=<DivBackward0>) tensor(2.7055, grad_fn=<DivBackward0>) torch.Size([3534])\n",
      "epoch:178 Res: 4925.500961 Loss 46.734310,loss1: 36.505398,loss2: 9.138268,loss3 1.090646\n",
      "tensor(2.1634, grad_fn=<DivBackward0>) tensor(2.7060, grad_fn=<DivBackward0>) torch.Size([3558])\n",
      "epoch:179 Res: 4841.574738 Loss 43.479965,loss1: 32.040405,loss2: 11.328517,loss3 0.111042\n",
      "tensor(2.1643, grad_fn=<DivBackward0>) tensor(2.7066, grad_fn=<DivBackward0>) torch.Size([3590])\n",
      "epoch:180 Res: 4813.780224 Loss 50.321510,loss1: 34.743034,loss2: 13.472563,loss3 2.105912\n",
      "tensor(2.1692, grad_fn=<DivBackward0>) tensor(2.7119, grad_fn=<DivBackward0>) torch.Size([3551])\n",
      "epoch:181 Res: 4839.228027 Loss 43.589909,loss1: 31.168581,loss2: 11.486282,loss3 0.935049\n",
      "tensor(2.1698, grad_fn=<DivBackward0>) tensor(2.7114, grad_fn=<DivBackward0>) torch.Size([3499])\n",
      "epoch:182 Res: 4773.993958 Loss 43.884975,loss1: 32.391151,loss2: 9.760347,loss3 1.733477\n",
      "tensor(2.1713, grad_fn=<DivBackward0>) tensor(2.7121, grad_fn=<DivBackward0>) torch.Size([3540])\n",
      "epoch:183 Res: 4790.701550 Loss 34.135311,loss1: 23.686670,loss2: 9.931816,loss3 0.516825\n",
      "tensor(2.1694, grad_fn=<DivBackward0>) tensor(2.7104, grad_fn=<DivBackward0>) torch.Size([3575])\n",
      "epoch:184 Res: 4737.827930 Loss 46.279270,loss1: 31.257574,loss2: 13.565043,loss3 1.456652\n",
      "tensor(2.1753, grad_fn=<DivBackward0>) tensor(2.7140, grad_fn=<DivBackward0>) torch.Size([3489])\n",
      "epoch:185 Res: 4652.860481 Loss 33.038670,loss1: 25.141098,loss2: 7.486187,loss3 0.411385\n",
      "tensor(2.1784, grad_fn=<DivBackward0>) tensor(2.7184, grad_fn=<DivBackward0>) torch.Size([3571])\n",
      "epoch:186 Res: 4689.610081 Loss 43.368935,loss1: 25.875423,loss2: 16.671320,loss3 0.822188\n",
      "tensor(2.1819, grad_fn=<DivBackward0>) tensor(2.7193, grad_fn=<DivBackward0>) torch.Size([3569])\n",
      "epoch:187 Res: 4713.979782 Loss 48.408829,loss1: 35.074963,loss2: 12.322859,loss3 1.011009\n",
      "tensor(2.1819, grad_fn=<DivBackward0>) tensor(2.7212, grad_fn=<DivBackward0>) torch.Size([3601])\n",
      "epoch:188 Res: 4754.717300 Loss 43.163567,loss1: 32.059361,loss2: 10.579690,loss3 0.524516\n",
      "tensor(2.1788, grad_fn=<DivBackward0>) tensor(2.7180, grad_fn=<DivBackward0>) torch.Size([3544])\n",
      "epoch:189 Res: 4670.558323 Loss 37.702454,loss1: 26.043415,loss2: 9.903757,loss3 1.755281\n",
      "tensor(2.1833, grad_fn=<DivBackward0>) tensor(2.7215, grad_fn=<DivBackward0>) torch.Size([3559])\n",
      "epoch:190 Res: 4656.032211 Loss 52.831863,loss1: 42.292427,loss2: 9.862553,loss3 0.676884\n",
      "tensor(2.1827, grad_fn=<DivBackward0>) tensor(2.7206, grad_fn=<DivBackward0>) torch.Size([3473])\n",
      "epoch:191 Res: 4738.508835 Loss 46.931728,loss1: 35.169140,loss2: 10.353998,loss3 1.408590\n",
      "tensor(2.1860, grad_fn=<DivBackward0>) tensor(2.7235, grad_fn=<DivBackward0>) torch.Size([3564])\n",
      "epoch:192 Res: 4581.298634 Loss 37.569187,loss1: 27.112356,loss2: 9.338714,loss3 1.118118\n",
      "tensor(2.1913, grad_fn=<DivBackward0>) tensor(2.7260, grad_fn=<DivBackward0>) torch.Size([3539])\n",
      "epoch:193 Res: 4607.258209 Loss 46.144936,loss1: 38.431141,loss2: 7.302239,loss3 0.411556\n",
      "tensor(2.1905, grad_fn=<DivBackward0>) tensor(2.7264, grad_fn=<DivBackward0>) torch.Size([3607])\n",
      "epoch:194 Res: 4674.592783 Loss 53.407108,loss1: 40.766159,loss2: 12.152969,loss3 0.487980\n",
      "tensor(2.1900, grad_fn=<DivBackward0>) tensor(2.7260, grad_fn=<DivBackward0>) torch.Size([3558])\n",
      "epoch:195 Res: 4621.547844 Loss 46.153706,loss1: 34.694153,loss2: 9.574024,loss3 1.885528\n",
      "tensor(2.1854, grad_fn=<DivBackward0>) tensor(2.7235, grad_fn=<DivBackward0>) torch.Size([3664])\n",
      "epoch:196 Res: 4586.444809 Loss 45.928699,loss1: 33.807568,loss2: 10.709742,loss3 1.411388\n",
      "tensor(2.1902, grad_fn=<DivBackward0>) tensor(2.7285, grad_fn=<DivBackward0>) torch.Size([3491])\n",
      "epoch:197 Res: 4653.922176 Loss 41.452805,loss1: 28.431740,loss2: 11.343495,loss3 1.677571\n",
      "tensor(2.1916, grad_fn=<DivBackward0>) tensor(2.7285, grad_fn=<DivBackward0>) torch.Size([3535])\n",
      "epoch:198 Res: 4459.307878 Loss 44.316143,loss1: 31.069588,loss2: 13.113798,loss3 0.132754\n",
      "tensor(2.1971, grad_fn=<DivBackward0>) tensor(2.7317, grad_fn=<DivBackward0>) torch.Size([3496])\n",
      "epoch:199 Res: 4550.279606 Loss 50.923050,loss1: 42.375565,loss2: 7.129182,loss3 1.418303\n",
      "tensor(2.1962, grad_fn=<DivBackward0>) tensor(2.7321, grad_fn=<DivBackward0>) torch.Size([3503])\n",
      "epoch:200 Res: 4522.638672 Loss 47.055687,loss1: 33.257343,loss2: 12.710817,loss3 1.087524\n",
      "tensor(2.1958, grad_fn=<DivBackward0>) tensor(2.7318, grad_fn=<DivBackward0>) torch.Size([3533])\n",
      "epoch:201 Res: 4570.499039 Loss 60.209698,loss1: 45.197807,loss2: 10.830497,loss3 4.181391\n",
      "tensor(2.1976, grad_fn=<DivBackward0>) tensor(2.7353, grad_fn=<DivBackward0>) torch.Size([3518])\n",
      "epoch:202 Res: 4607.034134 Loss 43.196259,loss1: 31.745411,loss2: 10.200874,loss3 1.249973\n",
      "tensor(2.2014, grad_fn=<DivBackward0>) tensor(2.7371, grad_fn=<DivBackward0>) torch.Size([3501])\n",
      "epoch:203 Res: 4446.891129 Loss 52.213703,loss1: 41.979271,loss2: 9.922777,loss3 0.311657\n",
      "tensor(2.2000, grad_fn=<DivBackward0>) tensor(2.7350, grad_fn=<DivBackward0>) torch.Size([3474])\n",
      "epoch:204 Res: 4434.192799 Loss 47.023411,loss1: 35.439232,loss2: 10.585010,loss3 0.999167\n",
      "tensor(2.2051, grad_fn=<DivBackward0>) tensor(2.7402, grad_fn=<DivBackward0>) torch.Size([3540])\n",
      "epoch:205 Res: 4491.953260 Loss 39.820045,loss1: 31.092411,loss2: 7.816008,loss3 0.911627\n",
      "tensor(2.2048, grad_fn=<DivBackward0>) tensor(2.7383, grad_fn=<DivBackward0>) torch.Size([3548])\n",
      "epoch:206 Res: 4436.290581 Loss 52.039341,loss1: 41.317242,loss2: 8.956244,loss3 1.765854\n",
      "tensor(2.2078, grad_fn=<DivBackward0>) tensor(2.7410, grad_fn=<DivBackward0>) torch.Size([3487])\n",
      "epoch:207 Res: 4422.331270 Loss 40.849995,loss1: 30.726660,loss2: 8.272527,loss3 1.850806\n",
      "tensor(2.2071, grad_fn=<DivBackward0>) tensor(2.7387, grad_fn=<DivBackward0>) torch.Size([3532])\n",
      "epoch:208 Res: 4531.616322 Loss 46.448143,loss1: 32.613510,loss2: 13.254243,loss3 0.580391\n",
      "tensor(2.2080, grad_fn=<DivBackward0>) tensor(2.7414, grad_fn=<DivBackward0>) torch.Size([3568])\n",
      "epoch:209 Res: 4336.548275 Loss 35.280754,loss1: 27.731800,loss2: 6.490517,loss3 1.058439\n",
      "tensor(2.2094, grad_fn=<DivBackward0>) tensor(2.7426, grad_fn=<DivBackward0>) torch.Size([3502])\n",
      "epoch:210 Res: 4364.056797 Loss 38.023449,loss1: 31.095928,loss2: 6.662143,loss3 0.265378\n",
      "tensor(2.2070, grad_fn=<DivBackward0>) tensor(2.7401, grad_fn=<DivBackward0>) torch.Size([3524])\n",
      "epoch:211 Res: 4425.657413 Loss 38.644848,loss1: 29.640434,loss2: 8.410849,loss3 0.593562\n",
      "tensor(2.2144, grad_fn=<DivBackward0>) tensor(2.7442, grad_fn=<DivBackward0>) torch.Size([3483])\n",
      "epoch:212 Res: 4342.331488 Loss 54.021500,loss1: 41.488422,loss2: 11.775808,loss3 0.757271\n",
      "tensor(2.2127, grad_fn=<DivBackward0>) tensor(2.7436, grad_fn=<DivBackward0>) torch.Size([3581])\n",
      "epoch:213 Res: 4404.987289 Loss 50.844124,loss1: 37.015850,loss2: 13.524305,loss3 0.303970\n",
      "tensor(2.2129, grad_fn=<DivBackward0>) tensor(2.7469, grad_fn=<DivBackward0>) torch.Size([3555])\n",
      "epoch:214 Res: 4386.522289 Loss 44.499180,loss1: 36.772068,loss2: 7.296942,loss3 0.430171\n",
      "tensor(2.2102, grad_fn=<DivBackward0>) tensor(2.7416, grad_fn=<DivBackward0>) torch.Size([3542])\n",
      "epoch:215 Res: 4320.196175 Loss 43.120090,loss1: 31.998314,loss2: 6.607163,loss3 4.514614\n",
      "tensor(2.2096, grad_fn=<DivBackward0>) tensor(2.7439, grad_fn=<DivBackward0>) torch.Size([3615])\n",
      "epoch:216 Res: 4342.961987 Loss 52.374748,loss1: 43.366207,loss2: 8.528269,loss3 0.480272\n",
      "tensor(2.2125, grad_fn=<DivBackward0>) tensor(2.7460, grad_fn=<DivBackward0>) torch.Size([3583])\n",
      "epoch:217 Res: 4402.673887 Loss 43.082233,loss1: 32.033112,loss2: 9.565701,loss3 1.483420\n",
      "tensor(2.2122, grad_fn=<DivBackward0>) tensor(2.7462, grad_fn=<DivBackward0>) torch.Size([3590])\n",
      "epoch:218 Res: 4427.007883 Loss 40.739105,loss1: 32.884308,loss2: 6.574168,loss3 1.280628\n",
      "tensor(2.2153, grad_fn=<DivBackward0>) tensor(2.7504, grad_fn=<DivBackward0>) torch.Size([3589])\n",
      "epoch:219 Res: 4271.213228 Loss 33.240952,loss1: 22.982323,loss2: 9.253182,loss3 1.005449\n",
      "tensor(2.2165, grad_fn=<DivBackward0>) tensor(2.7486, grad_fn=<DivBackward0>) torch.Size([3546])\n",
      "epoch:220 Res: 4225.658653 Loss 44.463669,loss1: 33.108021,loss2: 10.467590,loss3 0.888060\n",
      "tensor(2.2151, grad_fn=<DivBackward0>) tensor(2.7494, grad_fn=<DivBackward0>) torch.Size([3566])\n",
      "epoch:221 Res: 4377.202723 Loss 32.249603,loss1: 22.186565,loss2: 9.746193,loss3 0.316846\n",
      "tensor(2.2166, grad_fn=<DivBackward0>) tensor(2.7493, grad_fn=<DivBackward0>) torch.Size([3591])\n",
      "epoch:222 Res: 4286.635212 Loss 43.549541,loss1: 32.060143,loss2: 10.727602,loss3 0.761800\n",
      "tensor(2.2193, grad_fn=<DivBackward0>) tensor(2.7497, grad_fn=<DivBackward0>) torch.Size([3594])\n",
      "epoch:223 Res: 4220.371372 Loss 43.048256,loss1: 31.774517,loss2: 10.599127,loss3 0.674613\n",
      "tensor(2.2226, grad_fn=<DivBackward0>) tensor(2.7521, grad_fn=<DivBackward0>) torch.Size([3526])\n",
      "epoch:224 Res: 4222.146660 Loss 38.938049,loss1: 31.219988,loss2: 6.516449,loss3 1.201616\n",
      "tensor(2.2259, grad_fn=<DivBackward0>) tensor(2.7553, grad_fn=<DivBackward0>) torch.Size([3563])\n",
      "epoch:225 Res: 4207.409492 Loss 32.114693,loss1: 24.254080,loss2: 7.286517,loss3 0.574095\n",
      "tensor(2.2274, grad_fn=<DivBackward0>) tensor(2.7564, grad_fn=<DivBackward0>) torch.Size([3547])\n",
      "epoch:226 Res: 4284.069160 Loss 38.204704,loss1: 28.548534,loss2: 8.085694,loss3 1.570475\n",
      "tensor(2.2259, grad_fn=<DivBackward0>) tensor(2.7569, grad_fn=<DivBackward0>) torch.Size([3529])\n",
      "epoch:227 Res: 4155.869942 Loss 35.938225,loss1: 26.362051,loss2: 8.455230,loss3 1.120945\n",
      "tensor(2.2276, grad_fn=<DivBackward0>) tensor(2.7560, grad_fn=<DivBackward0>) torch.Size([3469])\n",
      "epoch:228 Res: 4233.063560 Loss 46.169350,loss1: 37.895905,loss2: 7.815259,loss3 0.458186\n",
      "tensor(2.2264, grad_fn=<DivBackward0>) tensor(2.7565, grad_fn=<DivBackward0>) torch.Size([3550])\n",
      "epoch:229 Res: 4241.387367 Loss 42.965126,loss1: 35.752766,loss2: 6.579314,loss3 0.633045\n",
      "tensor(2.2236, grad_fn=<DivBackward0>) tensor(2.7560, grad_fn=<DivBackward0>) torch.Size([3579])\n",
      "epoch:230 Res: 4095.633039 Loss 42.232643,loss1: 32.064163,loss2: 9.676023,loss3 0.492456\n",
      "tensor(2.2283, grad_fn=<DivBackward0>) tensor(2.7592, grad_fn=<DivBackward0>) torch.Size([3566])\n",
      "epoch:231 Res: 4120.680601 Loss 50.310642,loss1: 38.691696,loss2: 11.399886,loss3 0.219058\n",
      "tensor(2.2325, grad_fn=<DivBackward0>) tensor(2.7600, grad_fn=<DivBackward0>) torch.Size([3517])\n",
      "epoch:232 Res: 4172.768831 Loss 41.054729,loss1: 30.506136,loss2: 9.127007,loss3 1.421590\n",
      "tensor(2.2342, grad_fn=<DivBackward0>) tensor(2.7629, grad_fn=<DivBackward0>) torch.Size([3528])\n",
      "epoch:233 Res: 4140.756260 Loss 48.278812,loss1: 37.890545,loss2: 9.509953,loss3 0.878314\n",
      "tensor(2.2336, grad_fn=<DivBackward0>) tensor(2.7610, grad_fn=<DivBackward0>) torch.Size([3540])\n",
      "epoch:234 Res: 4113.537760 Loss 41.613209,loss1: 29.700726,loss2: 11.727221,loss3 0.185260\n",
      "tensor(2.2400, grad_fn=<DivBackward0>) tensor(2.7660, grad_fn=<DivBackward0>) torch.Size([3566])\n",
      "epoch:235 Res: 4136.869017 Loss 36.299603,loss1: 23.708508,loss2: 12.402142,loss3 0.188954\n",
      "tensor(2.2387, grad_fn=<DivBackward0>) tensor(2.7649, grad_fn=<DivBackward0>) torch.Size([3592])\n",
      "epoch:236 Res: 4174.206602 Loss 37.698460,loss1: 29.153170,loss2: 8.136343,loss3 0.408946\n",
      "tensor(2.2398, grad_fn=<DivBackward0>) tensor(2.7678, grad_fn=<DivBackward0>) torch.Size([3569])\n",
      "epoch:237 Res: 4128.104040 Loss 42.262459,loss1: 31.445459,loss2: 9.442623,loss3 1.374376\n",
      "tensor(2.2410, grad_fn=<DivBackward0>) tensor(2.7667, grad_fn=<DivBackward0>) torch.Size([3484])\n",
      "epoch:238 Res: 4147.591198 Loss 40.206444,loss1: 31.659725,loss2: 8.310522,loss3 0.236200\n",
      "tensor(2.2410, grad_fn=<DivBackward0>) tensor(2.7666, grad_fn=<DivBackward0>) torch.Size([3518])\n",
      "epoch:239 Res: 4005.785187 Loss 39.177578,loss1: 30.995556,loss2: 7.628093,loss3 0.553928\n",
      "tensor(2.2447, grad_fn=<DivBackward0>) tensor(2.7697, grad_fn=<DivBackward0>) torch.Size([3510])\n",
      "epoch:240 Res: 3989.922060 Loss 34.428921,loss1: 26.554880,loss2: 7.076388,loss3 0.797654\n",
      "tensor(2.2421, grad_fn=<DivBackward0>) tensor(2.7693, grad_fn=<DivBackward0>) torch.Size([3504])\n",
      "epoch:241 Res: 3983.748260 Loss 45.264297,loss1: 35.826130,loss2: 7.632535,loss3 1.805635\n",
      "tensor(2.2418, grad_fn=<DivBackward0>) tensor(2.7677, grad_fn=<DivBackward0>) torch.Size([3492])\n",
      "epoch:242 Res: 4128.737654 Loss 36.413166,loss1: 29.168001,loss2: 6.762003,loss3 0.483162\n",
      "tensor(2.2450, grad_fn=<DivBackward0>) tensor(2.7713, grad_fn=<DivBackward0>) torch.Size([3568])\n",
      "epoch:243 Res: 4107.307194 Loss 36.729652,loss1: 28.628357,loss2: 7.595082,loss3 0.506214\n",
      "tensor(2.2472, grad_fn=<DivBackward0>) tensor(2.7721, grad_fn=<DivBackward0>) torch.Size([3566])\n",
      "epoch:244 Res: 4021.113827 Loss 35.166019,loss1: 27.385614,loss2: 6.729856,loss3 1.050547\n",
      "tensor(2.2445, grad_fn=<DivBackward0>) tensor(2.7704, grad_fn=<DivBackward0>) torch.Size([3598])\n",
      "epoch:245 Res: 4013.655581 Loss 36.672108,loss1: 27.859354,loss2: 8.318176,loss3 0.494580\n",
      "tensor(2.2507, grad_fn=<DivBackward0>) tensor(2.7759, grad_fn=<DivBackward0>) torch.Size([3513])\n",
      "epoch:246 Res: 4012.224258 Loss 43.687557,loss1: 34.743008,loss2: 7.834816,loss3 1.109732\n",
      "tensor(2.2475, grad_fn=<DivBackward0>) tensor(2.7753, grad_fn=<DivBackward0>) torch.Size([3461])\n",
      "epoch:247 Res: 4117.088825 Loss 45.556553,loss1: 37.526703,loss2: 7.638954,loss3 0.390896\n",
      "tensor(2.2491, grad_fn=<DivBackward0>) tensor(2.7744, grad_fn=<DivBackward0>) torch.Size([3523])\n",
      "epoch:248 Res: 3929.026423 Loss 40.728279,loss1: 33.901875,loss2: 6.099805,loss3 0.726599\n",
      "tensor(2.2455, grad_fn=<DivBackward0>) tensor(2.7739, grad_fn=<DivBackward0>) torch.Size([3554])\n",
      "epoch:249 Res: 4091.836191 Loss 50.826183,loss1: 37.946060,loss2: 7.582948,loss3 5.297177\n",
      "tensor(2.2477, grad_fn=<DivBackward0>) tensor(2.7743, grad_fn=<DivBackward0>) torch.Size([3615])\n",
      "epoch:250 Res: 3933.816643 Loss 30.916639,loss1: 23.339275,loss2: 7.180127,loss3 0.397237\n",
      "tensor(2.2498, grad_fn=<DivBackward0>) tensor(2.7743, grad_fn=<DivBackward0>) torch.Size([3516])\n",
      "epoch:251 Res: 3953.193312 Loss 41.052723,loss1: 32.642090,loss2: 7.716415,loss3 0.694218\n",
      "tensor(2.2519, grad_fn=<DivBackward0>) tensor(2.7769, grad_fn=<DivBackward0>) torch.Size([3529])\n",
      "epoch:252 Res: 3992.276598 Loss 38.199036,loss1: 28.939768,loss2: 8.404380,loss3 0.854887\n",
      "tensor(2.2552, grad_fn=<DivBackward0>) tensor(2.7796, grad_fn=<DivBackward0>) torch.Size([3496])\n",
      "epoch:253 Res: 3874.271326 Loss 41.716457,loss1: 31.522287,loss2: 10.016726,loss3 0.177446\n",
      "tensor(2.2546, grad_fn=<DivBackward0>) tensor(2.7784, grad_fn=<DivBackward0>) torch.Size([3494])\n",
      "epoch:254 Res: 3879.862837 Loss 40.402157,loss1: 31.116409,loss2: 8.299177,loss3 0.986570\n",
      "tensor(2.2579, grad_fn=<DivBackward0>) tensor(2.7805, grad_fn=<DivBackward0>) torch.Size([3546])\n",
      "epoch:255 Res: 3972.476639 Loss 37.931404,loss1: 29.761665,loss2: 8.169741,loss3 0.000000\n",
      "tensor(2.2612, grad_fn=<DivBackward0>) tensor(2.7840, grad_fn=<DivBackward0>) torch.Size([3473])\n",
      "epoch:256 Res: 4000.895752 Loss 37.389198,loss1: 31.527298,loss2: 5.114641,loss3 0.747261\n",
      "tensor(2.2613, grad_fn=<DivBackward0>) tensor(2.7834, grad_fn=<DivBackward0>) torch.Size([3483])\n",
      "epoch:257 Res: 3916.944618 Loss 39.219322,loss1: 30.447462,loss2: 8.367925,loss3 0.403935\n",
      "tensor(2.2630, grad_fn=<DivBackward0>) tensor(2.7840, grad_fn=<DivBackward0>) torch.Size([3514])\n",
      "epoch:258 Res: 3981.423920 Loss 40.075134,loss1: 29.496681,loss2: 9.308319,loss3 1.270134\n",
      "tensor(2.2589, grad_fn=<DivBackward0>) tensor(2.7821, grad_fn=<DivBackward0>) torch.Size([3503])\n",
      "epoch:259 Res: 3944.973932 Loss 39.433868,loss1: 29.544510,loss2: 8.474203,loss3 1.415154\n",
      "tensor(2.2576, grad_fn=<DivBackward0>) tensor(2.7821, grad_fn=<DivBackward0>) torch.Size([3624])\n",
      "epoch:260 Res: 4003.229639 Loss 55.898514,loss1: 46.319031,loss2: 8.095069,loss3 1.484412\n",
      "tensor(2.2590, grad_fn=<DivBackward0>) tensor(2.7821, grad_fn=<DivBackward0>) torch.Size([3553])\n",
      "epoch:261 Res: 3887.076166 Loss 42.055988,loss1: 32.672192,loss2: 7.820272,loss3 1.563527\n",
      "tensor(2.2620, grad_fn=<DivBackward0>) tensor(2.7861, grad_fn=<DivBackward0>) torch.Size([3543])\n",
      "epoch:262 Res: 3803.861906 Loss 31.238739,loss1: 22.971750,loss2: 7.289652,loss3 0.977337\n",
      "tensor(2.2635, grad_fn=<DivBackward0>) tensor(2.7854, grad_fn=<DivBackward0>) torch.Size([3392])\n",
      "epoch:263 Res: 3842.166439 Loss 35.158802,loss1: 26.077692,loss2: 8.885012,loss3 0.196100\n",
      "tensor(2.2661, grad_fn=<DivBackward0>) tensor(2.7885, grad_fn=<DivBackward0>) torch.Size([3588])\n",
      "epoch:264 Res: 3837.805853 Loss 42.171421,loss1: 34.664825,loss2: 7.093763,loss3 0.412833\n",
      "tensor(2.2649, grad_fn=<DivBackward0>) tensor(2.7870, grad_fn=<DivBackward0>) torch.Size([3464])\n",
      "epoch:265 Res: 3811.274763 Loss 40.165775,loss1: 29.106266,loss2: 10.530358,loss3 0.529153\n",
      "tensor(2.2690, grad_fn=<DivBackward0>) tensor(2.7909, grad_fn=<DivBackward0>) torch.Size([3534])\n",
      "epoch:266 Res: 3828.836315 Loss 39.242878,loss1: 30.991371,loss2: 7.634467,loss3 0.617040\n",
      "tensor(2.2671, grad_fn=<DivBackward0>) tensor(2.7892, grad_fn=<DivBackward0>) torch.Size([3538])\n",
      "epoch:267 Res: 3782.961401 Loss 39.296589,loss1: 30.642912,loss2: 8.207228,loss3 0.446450\n",
      "tensor(2.2674, grad_fn=<DivBackward0>) tensor(2.7892, grad_fn=<DivBackward0>) torch.Size([3565])\n",
      "epoch:268 Res: 3762.393311 Loss 40.838577,loss1: 31.060320,loss2: 7.386059,loss3 2.392198\n",
      "tensor(2.2690, grad_fn=<DivBackward0>) tensor(2.7911, grad_fn=<DivBackward0>) torch.Size([3615])\n",
      "epoch:269 Res: 3816.866570 Loss 34.468456,loss1: 24.739788,loss2: 9.455042,loss3 0.273625\n",
      "tensor(2.2685, grad_fn=<DivBackward0>) tensor(2.7908, grad_fn=<DivBackward0>) torch.Size([3469])\n",
      "epoch:270 Res: 3770.241405 Loss 36.064480,loss1: 29.710022,loss2: 5.550160,loss3 0.804297\n",
      "tensor(2.2668, grad_fn=<DivBackward0>) tensor(2.7893, grad_fn=<DivBackward0>) torch.Size([3622])\n",
      "epoch:271 Res: 3780.415369 Loss 39.108768,loss1: 31.097151,loss2: 7.730458,loss3 0.281159\n",
      "tensor(2.2686, grad_fn=<DivBackward0>) tensor(2.7903, grad_fn=<DivBackward0>) torch.Size([3493])\n",
      "epoch:272 Res: 3858.860601 Loss 43.099731,loss1: 33.215080,loss2: 9.179813,loss3 0.704839\n",
      "tensor(2.2697, grad_fn=<DivBackward0>) tensor(2.7914, grad_fn=<DivBackward0>) torch.Size([3562])\n",
      "epoch:273 Res: 3824.212473 Loss 37.216320,loss1: 26.044060,loss2: 9.893023,loss3 1.279238\n",
      "tensor(2.2716, grad_fn=<DivBackward0>) tensor(2.7933, grad_fn=<DivBackward0>) torch.Size([3532])\n",
      "epoch:274 Res: 3793.430082 Loss 37.070229,loss1: 23.804544,loss2: 11.517090,loss3 1.748596\n",
      "tensor(2.2709, grad_fn=<DivBackward0>) tensor(2.7926, grad_fn=<DivBackward0>) torch.Size([3586])\n",
      "epoch:275 Res: 3800.952984 Loss 39.368546,loss1: 28.985735,loss2: 9.258415,loss3 1.124395\n",
      "tensor(2.2685, grad_fn=<DivBackward0>) tensor(2.7902, grad_fn=<DivBackward0>) torch.Size([3486])\n",
      "epoch:276 Res: 3706.785847 Loss 26.339951,loss1: 19.956261,loss2: 6.221102,loss3 0.162588\n",
      "tensor(2.2709, grad_fn=<DivBackward0>) tensor(2.7928, grad_fn=<DivBackward0>) torch.Size([3536])\n",
      "epoch:277 Res: 3653.958246 Loss 37.847893,loss1: 26.522551,loss2: 10.637661,loss3 0.687684\n"
     ]
    }
   ],
   "source": [
    "config = parse_args()\n",
    "dataset = load_processed(dataset_name=config[\"dataset\"], split=config[\"split\"])\n",
    "print(\"dataset loaded\")\n",
    "train = Train(args=config, dataset=dataset)\n",
    "train.doTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
